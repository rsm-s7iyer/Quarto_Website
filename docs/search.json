[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shishir Iyer",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "Homework1/notebook.html",
    "href": "Homework1/notebook.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA x and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo better understand what drives charitable behavior, the researchers varied three key components of the appeal letters:\nMatch Ratio: Some donors were told that their contributions would be matched by a donor at a 1:1, 2:1, or 3:1 rate. The idea was to see whether increasing the “bang for the buck” would lead to higher participation and donation amounts.\nMatch Threshold: The size of the matching fund was also randomized across $25,000, $50,000, $100,000, or left unspecified. This tested whether a larger leadership gift serves as a stronger signal of legitimacy or urgency.\nSuggested Donation Amounts: Each letter included an example donation amount that was either equal to the donor’s previous highest contribution, or 1.25× or 1.5× that amount. This was intended to test anchoring and reference point effects.\nEvery recipient in the experiment was a prior donor, ensuring that the sample had familiarity with the organization. The key outcomes measured were whether the recipient gave (gave) and how much they gave (amount). With this setup, the researchers were able to examine both extensive and intensive margins of charitable giving behavior, all in a real-world, high-stakes setting\n\nimport pandas as pd\nimport numpy as np\n\n\ndata = pd.read_stata(\"/home/jovyan/Quarto_Website/Homework1/karlan_list_2007.dta\")\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\ndata.to_csv(\"Karlan_list.csv\")\n\n\nfull_description =  data.describe()\nprint(full_description.transpose())\n\n                      count          mean           std            min  \\\ntreatment           50083.0      0.666813      0.471357       0.000000   \ncontrol             50083.0      0.333187      0.471357       0.000000   \nratio2              50083.0      0.222311      0.415803       0.000000   \nratio3              50083.0      0.222211      0.415736       0.000000   \nsize25              50083.0      0.166723      0.372732       0.000000   \nsize50              50083.0      0.166623      0.372643       0.000000   \nsize100             50083.0      0.166723      0.372732       0.000000   \nsizeno              50083.0      0.166743      0.372750       0.000000   \naskd1               50083.0      0.222311      0.415803       0.000000   \naskd2               50083.0      0.222291      0.415790       0.000000   \naskd3               50083.0      0.222211      0.415736       0.000000   \nask1                50083.0     71.501807    101.728936      25.000000   \nask2                50083.0     91.792724    127.252628      35.000000   \nask3                50083.0    111.046263    151.673562      50.000000   \namount              50083.0      0.915694      8.707393       0.000000   \ngave                50083.0      0.020646      0.142197       0.000000   \namountchange        50083.0    -52.672016   1267.097778 -200412.125000   \nhpa                 50083.0     59.384975     71.179871       0.000000   \nltmedmra            50083.0      0.493720      0.499966       0.000000   \nfreq                50083.0      8.039355     11.394454       0.000000   \nyears               50082.0      6.097540      5.503492       0.000000   \nyear5               50083.0      0.508815      0.499927       0.000000   \nmrm2                50082.0     13.007268     12.081403       0.000000   \ndormant             50083.0      0.523471      0.499454       0.000000   \nfemale              48972.0      0.277669      0.447854       0.000000   \ncouple              48935.0      0.091897      0.288884       0.000000   \nstate50one          50083.0      0.000998      0.031581       0.000000   \nnonlit              49631.0      2.473918      1.961528       0.000000   \ncases               49631.0      1.499768      1.155140       0.000000   \nstatecnt            50083.0      5.998820      5.745993       0.001995   \nstateresponse       50083.0      0.020627      0.005171       0.000000   \nstateresponset      50083.0      0.021989      0.006257       0.000000   \nstateresponsec      50080.0      0.017717      0.007516       0.000000   \nstateresponsetminc  50080.0      0.004273      0.009112      -0.047619   \nperbush             50048.0      0.487940      0.078733       0.090909   \nclose25             50048.0      0.185702      0.388870       0.000000   \nred0                50048.0      0.404452      0.490791       0.000000   \nblue0               50048.0      0.595548      0.490791       0.000000   \nredcty              49978.0      0.510245      0.499900       0.000000   \nbluecty             49978.0      0.488715      0.499878       0.000000   \npwhite              48217.0      0.819599      0.168560       0.009418   \npblack              48047.0      0.086710      0.135868       0.000000   \npage18_39           48217.0      0.321694      0.103039       0.000000   \nave_hh_sz           48221.0      2.429012      0.378105       0.000000   \nmedian_hhincome     48209.0  54815.700533  22027.316665    5000.000000   \npowner              48214.0      0.669418      0.193405       0.000000   \npsch_atlstba        48215.0      0.391661      0.186599       0.000000   \npop_propurban       48217.0      0.871968      0.258633       0.000000   \n\n                             25%           50%           75%            max  \ntreatment               0.000000      1.000000      1.000000       1.000000  \ncontrol                 0.000000      0.000000      1.000000       1.000000  \nratio2                  0.000000      0.000000      0.000000       1.000000  \nratio3                  0.000000      0.000000      0.000000       1.000000  \nsize25                  0.000000      0.000000      0.000000       1.000000  \nsize50                  0.000000      0.000000      0.000000       1.000000  \nsize100                 0.000000      0.000000      0.000000       1.000000  \nsizeno                  0.000000      0.000000      0.000000       1.000000  \naskd1                   0.000000      0.000000      0.000000       1.000000  \naskd2                   0.000000      0.000000      0.000000       1.000000  \naskd3                   0.000000      0.000000      0.000000       1.000000  \nask1                   35.000000     45.000000     65.000000    1500.000000  \nask2                   45.000000     60.000000     85.000000    1875.000000  \nask3                   55.000000     70.000000    100.000000    2250.000000  \namount                  0.000000      0.000000      0.000000     400.000000  \ngave                    0.000000      0.000000      0.000000       1.000000  \namountchange          -50.000000    -30.000000    -25.000000     275.000000  \nhpa                    30.000000     45.000000     60.000000    1000.000000  \nltmedmra                0.000000      0.000000      1.000000       1.000000  \nfreq                    2.000000      4.000000     10.000000     218.000000  \nyears                   2.000000      5.000000      9.000000      95.000000  \nyear5                   0.000000      1.000000      1.000000       1.000000  \nmrm2                    4.000000      8.000000     19.000000     168.000000  \ndormant                 0.000000      1.000000      1.000000       1.000000  \nfemale                  0.000000      0.000000      1.000000       1.000000  \ncouple                  0.000000      0.000000      0.000000       1.000000  \nstate50one              0.000000      0.000000      0.000000       1.000000  \nnonlit                  1.000000      3.000000      4.000000       6.000000  \ncases                   1.000000      1.000000      2.000000       4.000000  \nstatecnt                1.833234      3.538799      9.607021      17.368841  \nstateresponse           0.018163      0.019710      0.023048       0.076923  \nstateresponset          0.018493      0.021697      0.024703       0.111111  \nstateresponsec          0.012862      0.019881      0.020806       0.052632  \nstateresponsetminc     -0.001388      0.001779      0.010545       0.111111  \nperbush                 0.444444      0.484848      0.525253       0.731959  \nclose25                 0.000000      0.000000      0.000000       1.000000  \nred0                    0.000000      0.000000      1.000000       1.000000  \nblue0                   0.000000      1.000000      1.000000       1.000000  \nredcty                  0.000000      1.000000      1.000000       1.000000  \nbluecty                 0.000000      0.000000      1.000000       1.000000  \npwhite                  0.755845      0.872797      0.938827       1.000000  \npblack                  0.014729      0.036554      0.090882       0.989622  \npage18_39               0.258311      0.305534      0.369132       0.997544  \nave_hh_sz               2.210000      2.440000      2.660000       5.270000  \nmedian_hhincome     39181.000000  50673.000000  66005.000000  200001.000000  \npowner                  0.560222      0.712296      0.816798       1.000000  \npsch_atlstba            0.235647      0.373744      0.530036       1.000000  \npop_propurban           0.884929      1.000000      1.000000       1.000000  \n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\n# Check for missing values\nmissing_values = data.isnull().sum()\nprint(\"Missing values in each column:\")\nprint(missing_values)\n\nMissing values in each column:\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\n\n# Check for duplicates\nduplicates = data.duplicated().sum()\nprint(f\"Number of duplicate rows: {duplicates}\")\n\nNumber of duplicate rows: 30\n\n\n\n    \n\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load the data\n\n# Variables to test\nvars_to_test = ['mrm2', 'freq', 'female', 'hpa']\n\n# Drop missing values for selected variables\ndata_clean = data[['treatment'] + vars_to_test].dropna()\n\nresults = []\n\nfor var in vars_to_test:\n    # Separate groups\n    treat_group = data_clean[data_clean['treatment'] == 1][var]\n    control_group = data_clean[data_clean['treatment'] == 0][var]\n\n    # T-test\n    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)\n\n    # Linear regression\n    formula = f\"{var} ~ treatment\"\n    model = smf.ols(formula, data=data_clean).fit()\n    coef = model.params['treatment']\n    reg_pval = model.pvalues['treatment']\n\n    # Store result\n    results.append({\n        \"Variable\": var,\n        \"T-test t-stat\": round(t_stat, 4),\n        \"T-test p-value\": round(t_pval, 4),\n        \"Regression coef\": round(coef, 4),\n        \"Regression p-value\": round(reg_pval, 4)\n    })\n\n# Convert to DataFrame to display\npd.DataFrame(results)\n\n\n\n\n\n\n\n\nVariable\nT-test t-stat\nT-test p-value\nRegression coef\nRegression p-value\n\n\n\n\n0\nmrm2\n0.0764\n0.9391\n0.0088\n0.9391\n\n\n1\nfreq\n-0.0597\n0.9524\n-0.0066\n0.9524\n\n\n2\nfemale\n-1.7587\n0.0786\n-0.0076\n0.0778\n\n\n3\nhpa\n1.0085\n0.3132\n0.6635\n0.3274\n\n\n\n\n\n\n\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load your dataset\n\n# T-test\ntreat = data[data['treatment'] == 1]['gave']\ncontrol = data[data['treatment'] == 0]['gave']\nt_stat, p_val = ttest_ind(treat, control, equal_var=False)\n\n# Means\ntreat_mean = treat.mean()\ncontrol_mean = control.mean()\ndiff = treat_mean - control_mean\n\n# Linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=data).fit()\nreg_coef = model.params[\"treatment\"]\nreg_pval = model.pvalues[\"treatment\"]\n\n# Print results\nprint(\"=== T-Test: Difference in Proportion Donating ===\")\nprint(f\"Control Mean:       {control_mean:.4f}\")\nprint(f\"Treatment Mean:     {treat_mean:.4f}\")\nprint(f\"Difference:         {diff:.4f}\")\nprint(f\"T-statistic:        {t_stat:.4f}\")\nprint(f\"P-value:            {p_val:.4f}\")\n\nprint(\"\\n=== Linear Regression ===\")\nprint(f\"Treatment Coef:     {reg_coef:.4f}\")\nprint(f\"Regression P-value: {reg_pval:.4f}\")\n\n=== T-Test: Difference in Proportion Donating ===\nControl Mean:       0.0179\nTreatment Mean:     0.0220\nDifference:         0.0042\nT-statistic:        3.2095\nP-value:            0.0013\n\n=== Linear Regression ===\nTreatment Coef:     0.0042\nRegression P-value: 0.0019\n\n\n\n# Run a probit regression: gave ~ treatment\nprobit_model = smf.probit(\"gave ~ treatment\", data=data).fit()\n\n# Display result\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Mon, 21 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        20:35:16   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n=============================================================================="
  },
  {
    "objectID": "Homework1/notebook.html#introduction",
    "href": "Homework1/notebook.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA x and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo better understand what drives charitable behavior, the researchers varied three key components of the appeal letters:\nMatch Ratio: Some donors were told that their contributions would be matched by a donor at a 1:1, 2:1, or 3:1 rate. The idea was to see whether increasing the “bang for the buck” would lead to higher participation and donation amounts.\nMatch Threshold: The size of the matching fund was also randomized across $25,000, $50,000, $100,000, or left unspecified. This tested whether a larger leadership gift serves as a stronger signal of legitimacy or urgency.\nSuggested Donation Amounts: Each letter included an example donation amount that was either equal to the donor’s previous highest contribution, or 1.25× or 1.5× that amount. This was intended to test anchoring and reference point effects.\nEvery recipient in the experiment was a prior donor, ensuring that the sample had familiarity with the organization. The key outcomes measured were whether the recipient gave (gave) and how much they gave (amount). With this setup, the researchers were able to examine both extensive and intensive margins of charitable giving behavior, all in a real-world, high-stakes setting\n\nimport pandas as pd\nimport numpy as np\n\n\ndata = pd.read_stata(\"/home/jovyan/Quarto_Website/Homework1/karlan_list_2007.dta\")\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\ndata.to_csv(\"Karlan_list.csv\")\n\n\nfull_description =  data.describe()\nprint(full_description.transpose())\n\n                      count          mean           std            min  \\\ntreatment           50083.0      0.666813      0.471357       0.000000   \ncontrol             50083.0      0.333187      0.471357       0.000000   \nratio2              50083.0      0.222311      0.415803       0.000000   \nratio3              50083.0      0.222211      0.415736       0.000000   \nsize25              50083.0      0.166723      0.372732       0.000000   \nsize50              50083.0      0.166623      0.372643       0.000000   \nsize100             50083.0      0.166723      0.372732       0.000000   \nsizeno              50083.0      0.166743      0.372750       0.000000   \naskd1               50083.0      0.222311      0.415803       0.000000   \naskd2               50083.0      0.222291      0.415790       0.000000   \naskd3               50083.0      0.222211      0.415736       0.000000   \nask1                50083.0     71.501807    101.728936      25.000000   \nask2                50083.0     91.792724    127.252628      35.000000   \nask3                50083.0    111.046263    151.673562      50.000000   \namount              50083.0      0.915694      8.707393       0.000000   \ngave                50083.0      0.020646      0.142197       0.000000   \namountchange        50083.0    -52.672016   1267.097778 -200412.125000   \nhpa                 50083.0     59.384975     71.179871       0.000000   \nltmedmra            50083.0      0.493720      0.499966       0.000000   \nfreq                50083.0      8.039355     11.394454       0.000000   \nyears               50082.0      6.097540      5.503492       0.000000   \nyear5               50083.0      0.508815      0.499927       0.000000   \nmrm2                50082.0     13.007268     12.081403       0.000000   \ndormant             50083.0      0.523471      0.499454       0.000000   \nfemale              48972.0      0.277669      0.447854       0.000000   \ncouple              48935.0      0.091897      0.288884       0.000000   \nstate50one          50083.0      0.000998      0.031581       0.000000   \nnonlit              49631.0      2.473918      1.961528       0.000000   \ncases               49631.0      1.499768      1.155140       0.000000   \nstatecnt            50083.0      5.998820      5.745993       0.001995   \nstateresponse       50083.0      0.020627      0.005171       0.000000   \nstateresponset      50083.0      0.021989      0.006257       0.000000   \nstateresponsec      50080.0      0.017717      0.007516       0.000000   \nstateresponsetminc  50080.0      0.004273      0.009112      -0.047619   \nperbush             50048.0      0.487940      0.078733       0.090909   \nclose25             50048.0      0.185702      0.388870       0.000000   \nred0                50048.0      0.404452      0.490791       0.000000   \nblue0               50048.0      0.595548      0.490791       0.000000   \nredcty              49978.0      0.510245      0.499900       0.000000   \nbluecty             49978.0      0.488715      0.499878       0.000000   \npwhite              48217.0      0.819599      0.168560       0.009418   \npblack              48047.0      0.086710      0.135868       0.000000   \npage18_39           48217.0      0.321694      0.103039       0.000000   \nave_hh_sz           48221.0      2.429012      0.378105       0.000000   \nmedian_hhincome     48209.0  54815.700533  22027.316665    5000.000000   \npowner              48214.0      0.669418      0.193405       0.000000   \npsch_atlstba        48215.0      0.391661      0.186599       0.000000   \npop_propurban       48217.0      0.871968      0.258633       0.000000   \n\n                             25%           50%           75%            max  \ntreatment               0.000000      1.000000      1.000000       1.000000  \ncontrol                 0.000000      0.000000      1.000000       1.000000  \nratio2                  0.000000      0.000000      0.000000       1.000000  \nratio3                  0.000000      0.000000      0.000000       1.000000  \nsize25                  0.000000      0.000000      0.000000       1.000000  \nsize50                  0.000000      0.000000      0.000000       1.000000  \nsize100                 0.000000      0.000000      0.000000       1.000000  \nsizeno                  0.000000      0.000000      0.000000       1.000000  \naskd1                   0.000000      0.000000      0.000000       1.000000  \naskd2                   0.000000      0.000000      0.000000       1.000000  \naskd3                   0.000000      0.000000      0.000000       1.000000  \nask1                   35.000000     45.000000     65.000000    1500.000000  \nask2                   45.000000     60.000000     85.000000    1875.000000  \nask3                   55.000000     70.000000    100.000000    2250.000000  \namount                  0.000000      0.000000      0.000000     400.000000  \ngave                    0.000000      0.000000      0.000000       1.000000  \namountchange          -50.000000    -30.000000    -25.000000     275.000000  \nhpa                    30.000000     45.000000     60.000000    1000.000000  \nltmedmra                0.000000      0.000000      1.000000       1.000000  \nfreq                    2.000000      4.000000     10.000000     218.000000  \nyears                   2.000000      5.000000      9.000000      95.000000  \nyear5                   0.000000      1.000000      1.000000       1.000000  \nmrm2                    4.000000      8.000000     19.000000     168.000000  \ndormant                 0.000000      1.000000      1.000000       1.000000  \nfemale                  0.000000      0.000000      1.000000       1.000000  \ncouple                  0.000000      0.000000      0.000000       1.000000  \nstate50one              0.000000      0.000000      0.000000       1.000000  \nnonlit                  1.000000      3.000000      4.000000       6.000000  \ncases                   1.000000      1.000000      2.000000       4.000000  \nstatecnt                1.833234      3.538799      9.607021      17.368841  \nstateresponse           0.018163      0.019710      0.023048       0.076923  \nstateresponset          0.018493      0.021697      0.024703       0.111111  \nstateresponsec          0.012862      0.019881      0.020806       0.052632  \nstateresponsetminc     -0.001388      0.001779      0.010545       0.111111  \nperbush                 0.444444      0.484848      0.525253       0.731959  \nclose25                 0.000000      0.000000      0.000000       1.000000  \nred0                    0.000000      0.000000      1.000000       1.000000  \nblue0                   0.000000      1.000000      1.000000       1.000000  \nredcty                  0.000000      1.000000      1.000000       1.000000  \nbluecty                 0.000000      0.000000      1.000000       1.000000  \npwhite                  0.755845      0.872797      0.938827       1.000000  \npblack                  0.014729      0.036554      0.090882       0.989622  \npage18_39               0.258311      0.305534      0.369132       0.997544  \nave_hh_sz               2.210000      2.440000      2.660000       5.270000  \nmedian_hhincome     39181.000000  50673.000000  66005.000000  200001.000000  \npowner                  0.560222      0.712296      0.816798       1.000000  \npsch_atlstba            0.235647      0.373744      0.530036       1.000000  \npop_propurban           0.884929      1.000000      1.000000       1.000000  \n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\n# Check for missing values\nmissing_values = data.isnull().sum()\nprint(\"Missing values in each column:\")\nprint(missing_values)\n\nMissing values in each column:\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\n\n# Check for duplicates\nduplicates = data.duplicated().sum()\nprint(f\"Number of duplicate rows: {duplicates}\")\n\nNumber of duplicate rows: 30\n\n\n\n    \n\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load the data\n\n# Variables to test\nvars_to_test = ['mrm2', 'freq', 'female', 'hpa']\n\n# Drop missing values for selected variables\ndata_clean = data[['treatment'] + vars_to_test].dropna()\n\nresults = []\n\nfor var in vars_to_test:\n    # Separate groups\n    treat_group = data_clean[data_clean['treatment'] == 1][var]\n    control_group = data_clean[data_clean['treatment'] == 0][var]\n\n    # T-test\n    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)\n\n    # Linear regression\n    formula = f\"{var} ~ treatment\"\n    model = smf.ols(formula, data=data_clean).fit()\n    coef = model.params['treatment']\n    reg_pval = model.pvalues['treatment']\n\n    # Store result\n    results.append({\n        \"Variable\": var,\n        \"T-test t-stat\": round(t_stat, 4),\n        \"T-test p-value\": round(t_pval, 4),\n        \"Regression coef\": round(coef, 4),\n        \"Regression p-value\": round(reg_pval, 4)\n    })\n\n# Convert to DataFrame to display\npd.DataFrame(results)\n\n\n\n\n\n\n\n\nVariable\nT-test t-stat\nT-test p-value\nRegression coef\nRegression p-value\n\n\n\n\n0\nmrm2\n0.0764\n0.9391\n0.0088\n0.9391\n\n\n1\nfreq\n-0.0597\n0.9524\n-0.0066\n0.9524\n\n\n2\nfemale\n-1.7587\n0.0786\n-0.0076\n0.0778\n\n\n3\nhpa\n1.0085\n0.3132\n0.6635\n0.3274\n\n\n\n\n\n\n\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load your dataset\n\n# T-test\ntreat = data[data['treatment'] == 1]['gave']\ncontrol = data[data['treatment'] == 0]['gave']\nt_stat, p_val = ttest_ind(treat, control, equal_var=False)\n\n# Means\ntreat_mean = treat.mean()\ncontrol_mean = control.mean()\ndiff = treat_mean - control_mean\n\n# Linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=data).fit()\nreg_coef = model.params[\"treatment\"]\nreg_pval = model.pvalues[\"treatment\"]\n\n# Print results\nprint(\"=== T-Test: Difference in Proportion Donating ===\")\nprint(f\"Control Mean:       {control_mean:.4f}\")\nprint(f\"Treatment Mean:     {treat_mean:.4f}\")\nprint(f\"Difference:         {diff:.4f}\")\nprint(f\"T-statistic:        {t_stat:.4f}\")\nprint(f\"P-value:            {p_val:.4f}\")\n\nprint(\"\\n=== Linear Regression ===\")\nprint(f\"Treatment Coef:     {reg_coef:.4f}\")\nprint(f\"Regression P-value: {reg_pval:.4f}\")\n\n=== T-Test: Difference in Proportion Donating ===\nControl Mean:       0.0179\nTreatment Mean:     0.0220\nDifference:         0.0042\nT-statistic:        3.2095\nP-value:            0.0013\n\n=== Linear Regression ===\nTreatment Coef:     0.0042\nRegression P-value: 0.0019\n\n\n\n# Run a probit regression: gave ~ treatment\nprobit_model = smf.probit(\"gave ~ treatment\", data=data).fit()\n\n# Display result\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Mon, 21 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        20:35:16   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n=============================================================================="
  },
  {
    "objectID": "Homework1/hw1_questions.html",
    "href": "Homework1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In 2007, economists Dean Karlan (Yale University) and John List (University of Chicago) conducted one of the most influential field experiments in the study of charitable giving. The experiment aimed to test how various fundraising letter strategies affected donation behavior.\nAs part of the study, the researchers sent out 50,000 direct mail fundraising letters to previous donors of a U.S. nonprofit organization. Each recipient was randomly assigned to receive one of several types of letters, enabling the authors to identify causal effects of different fundraising tactics.\nThe paper, published in the American Economic Review, and the associated dataset are available via the AEA website and from Harvard’s Dataverse.\nTo better understand what motivates charitable behavior, Karlan and List varied three core features of the letters:\n\nMatch Ratio: Donors were told their gift would be matched at a ratio of 1:1, 2:1, or 3:1 by a leadership donor.\nMatch Threshold: The maximum amount that the leadership donor would contribute was either $25,000, $50,000, $100,000, or left unstated.\nSuggested Donation Amounts: The reply card included a suggested donation amount based on the donor’s past giving — either 1.00×, 1.25×, or 1.50× of their previous highest contribution.\n\nBecause all recipients were prior donors, the organization had rich historical information to tailor these treatments. The key outcomes of interest were: - Whether a person donated at all (gave) - And if they did, how much they donated (amount)\nThis project replicates Karlan and List’s main findings, with a particular focus on estimating the effects of match ratio, threshold size, and suggested ask amounts on donation behavior. Both extensive (whether someone donates) and intensive (how much they donate) margins of behavior are explored in a real-world, randomized setting."
  },
  {
    "objectID": "Homework1/hw1_questions.html#introduction",
    "href": "Homework1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In 2007, economists Dean Karlan (Yale University) and John List (University of Chicago) conducted one of the most influential field experiments in the study of charitable giving. The experiment aimed to test how various fundraising letter strategies affected donation behavior.\nAs part of the study, the researchers sent out 50,000 direct mail fundraising letters to previous donors of a U.S. nonprofit organization. Each recipient was randomly assigned to receive one of several types of letters, enabling the authors to identify causal effects of different fundraising tactics.\nThe paper, published in the American Economic Review, and the associated dataset are available via the AEA website and from Harvard’s Dataverse.\nTo better understand what motivates charitable behavior, Karlan and List varied three core features of the letters:\n\nMatch Ratio: Donors were told their gift would be matched at a ratio of 1:1, 2:1, or 3:1 by a leadership donor.\nMatch Threshold: The maximum amount that the leadership donor would contribute was either $25,000, $50,000, $100,000, or left unstated.\nSuggested Donation Amounts: The reply card included a suggested donation amount based on the donor’s past giving — either 1.00×, 1.25×, or 1.50× of their previous highest contribution.\n\nBecause all recipients were prior donors, the organization had rich historical information to tailor these treatments. The key outcomes of interest were: - Whether a person donated at all (gave) - And if they did, how much they donated (amount)\nThis project replicates Karlan and List’s main findings, with a particular focus on estimating the effects of match ratio, threshold size, and suggested ask amounts on donation behavior. Both extensive (whether someone donates) and intensive (how much they donate) margins of behavior are explored in a real-world, randomized setting."
  },
  {
    "objectID": "Homework1/hw1_questions.html#data",
    "href": "Homework1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset consists of 50,083 observations and 52 variables, each corresponding to a prior donor who received a fundraising letter as part of the Karlan and List (2007) field experiment. The core goal of the experiment was to test the impact of matching grants and suggested donation amounts on charitable giving behavior.\nEach row contains information about:\n\nTreatment assignment (e.g., whether the donor was offered a matching grant and what kind),\nOutcome behavior (whether they gave, and how much),\nPast donation history (e.g., previous contribution amounts and frequency),\nDemographics (e.g., gender, couple status), and\nGeographic and political context (e.g., state-level voting patterns and zip code demographics).\n\nThere are no missing values in the key outcome or treatment variables (such as treatment, gave, and amount), which is crucial for clean experimental analysis.\n\nKey Variables\n\ntreatment, control: Indicators for experimental assignment\n\ngave (binary): Whether the recipient donated after receiving the letter\n\namount (continuous): How much the recipient donated\n\nratio2, ratio3: Whether the donor was offered a 2:1 or 3:1 matching grant (1:1 is the omitted category)\n\nsize25, size50, size100: Match pool size indicators\n\naskd1, askd2, askd3: Suggested donation amounts based on a multiple of the donor’s highest previous contribution\n\nfreq, mrm2, years, hpa: Past donation frequency, recency, and highest previous amount\n\nfemale, couple: Donor demographics\n\nperbush, red0, blue0: State-level political alignment in the 2004 U.S. presidential election\n\nZip-code level variables: pwhite (percent white), median_hhincome, pop_propurban, and others provide socioeconomic context\n\n\n\nMissing Data\nMost variables have complete data. A few exceptions:\n\nfemale, couple: Missing in approximately 2% of rows\n\nnonlit, cases: Missing in less than 1%\n\nZip-code demographics (pwhite, pblack, page18_39, median_hhincome, etc.): Missing in\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code"
  },
  {
    "objectID": "Homework1/hw1_questions.html#experimental-results",
    "href": "Homework1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Calculate donation rates\ngrouped = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ngrouped[\"group\"] = grouped[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\n# Plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(grouped[\"group\"], grouped[\"gave\"], color=['#add8e6', '#00008b'])\n\n# Add value labels\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.001,\n             f\"{height:.3f}\", ha='center', va='bottom', fontsize=10)\n\n# Aesthetics\nplt.ylim(0, grouped[\"gave\"].max() + 0.01)\nplt.ylabel(\"Proportion Who Donated\", fontsize=11)\nplt.title(\"Donation Rate by Group\", fontsize=13)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.tight_layout()\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n\nplt.show()\n\n\n\n\n\nFigure 1: Bar plots of proportion of people who donated\n\n\n\n\n\n\n\n\n\nTo assess whether the matching grant offer increased the probability of giving, I ran a t-test and a bivariate linear regression comparing donation rates (gave) between treatment and control groups.\n\n\n\n\n\n\n\n\nCode\n# T-test\ntreat = df[df['treatment'] == 1]['gave']\ncontrol = df[df['treatment'] == 0]['gave']\nt_stat, p_val = ttest_ind(treat, control, equal_var=False)\n\n# Means\ntreat_mean = treat.mean()\ncontrol_mean = control.mean()\ndiff = treat_mean - control_mean\n\n# Linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\nreg_coef = model.params[\"treatment\"]\nreg_pval = model.pvalues[\"treatment\"]\n\n# Print results\nprint(\"=== T-Test: Difference in Proportion Donating ===\")\nprint(f\"Control Mean:       {control_mean:.4f}\")\nprint(f\"Treatment Mean:     {treat_mean:.4f}\")\nprint(f\"Difference:         {diff:.4f}\")\nprint(f\"T-statistic:        {t_stat:.4f}\")\nprint(f\"P-value:            {p_val:.4f}\")\n\nprint(\"\\n=== Linear Regression ===\")\nprint(f\"Treatment Coef:     {reg_coef:.4f}\")\nprint(f\"Regression P-value: {reg_pval:.4f}\")\n\n\n=== T-Test: Difference in Proportion Donating ===\nControl Mean:       0.0179\nTreatment Mean:     0.0220\nDifference:         0.0042\nT-statistic:        3.2095\nP-value:            0.0013\n\n=== Linear Regression ===\nTreatment Coef:     0.0042\nRegression P-value: 0.0019\n\n\n\n\n\n\n\nInterpretation\nDespite the small absolute difference, the matching grant led to a statistically significant increase in donation probability. This suggests that people are motivated by the idea of leverage — knowing their gift would be matched made them more likely to act.\nIn plain terms: the framing of a donation appeal matters. Even if the personal cost remains the same, the perception of greater impact (e.g., “my $50 becomes $100”) can effectively nudge more people into giving.\n\n\n\nProbit Regression: Treatment Effect on Donation Likelihood\nTo further confirm the treatment’s effect on donation behavior, I ran a probit regression with gave as the dependent variable and treatment as the only explanatory variable. This mirrors Column (1) of Table 3 in Karlan and List (2007).\n\n\n\n\n\n\n\n\nCode\n# Run a probit regression: gave ~ treatment\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit()\n\n# Extract treatment row as a DataFrame with named index\nsummary_df = probit_model.summary2().tables[1].loc[[\"treatment\"], [\"Coef.\", \"Std.Err.\", \"z\", \"P&gt;|z|\"]]\nsummary_df.columns = [\"Coefficient\", \"Standard Error\", \"z-score\", \"P-value\"]\nsummary_df.index.name = \"Variable\"\n\n# Display with 'treatment' as row label\nsummary_df\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\n\n\n\n\n\n\nCoefficient\nStandard Error\nz-score\nP-value\n\n\nVariable\n\n\n\n\n\n\n\n\ntreatment\n0.086785\n0.027879\n3.11293\n0.001852\n\n\n\n\n\n\n\n\n\n\nThe results aligns closely with the original paper, where the coefficient is also ~0.004 on the probability scale, confirming that the match offer significantly increases the probability of donation.\n\n\nInterpretation\nThe result suggests that receiving a matching grant message statistically increases the latent probability of making a donation. While the effect size is small in absolute terms, it is significant and supports the idea that framing matters — donors are more likely to respond when they perceive their contribution will have greater leverage or impact.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nTo assess whether higher match ratios increased the probability of donation, I compared donation rates across 1:1, 2:1, and 3:1 match offers using a series of t-tests.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\n\n# Keep only treated group\ndf_treated = df[df[\"treatment\"] == 1].copy()\n\n# Define 1:1 match group\ndf_treated[\"ratio1\"] = ((df_treated[\"ratio2\"] == 0) & (df_treated[\"ratio3\"] == 0)).astype(int)\n\n# Drop rows with missing values in relevant columns\ndf_treated = df_treated.dropna(subset=[\"gave\", \"ratio2\", \"ratio3\"])\n\n# Extract 'gave' by match ratio group\ngave_1_1 = df_treated[df_treated[\"ratio1\"] == 1][\"gave\"]\ngave_2_1 = df_treated[df_treated[\"ratio2\"] == 1][\"gave\"]\ngave_3_1 = df_treated[df_treated[\"ratio3\"] == 1][\"gave\"]\n\n# Compute donation rates\nmeans_df = pd.DataFrame({\n    \"Match Ratio\": [\"1:1 Match\", \"2:1 Match\", \"3:1 Match\"],\n    \"Donation Rate\": [gave_1_1.mean(), gave_2_1.mean(), gave_3_1.mean()]\n}).round(4)\n\n# Compute T-test p-values\nttest_df = pd.DataFrame({\n    \"Comparison\": [\"1:1 vs 2:1\", \"2:1 vs 3:1\", \"1:1 vs 3:1\"],\n    \"P-value\": [\n        ttest_ind(gave_1_1, gave_2_1, equal_var=False).pvalue,\n        ttest_ind(gave_2_1, gave_3_1, equal_var=False).pvalue,\n        ttest_ind(gave_1_1, gave_3_1, equal_var=False).pvalue\n    ]\n}).round(4)\n\n# Show both as tables\nmeans_df, ttest_df\n\n\n(  Match Ratio  Donation Rate\n 0   1:1 Match         0.0207\n 1   2:1 Match         0.0226\n 2   3:1 Match         0.0227,\n    Comparison  P-value\n 0  1:1 vs 2:1   0.3345\n 1  2:1 vs 3:1   0.9600\n 2  1:1 vs 3:1   0.3101)\n\n\n\n\n\n\n\nInterpretation\nThese results support the authors’ statement in the paper:\n\n“Larger match ratios (i.e., $3:$1 and $2:$1) relative to a smaller match ratio ($1:$1) had no additional impact.”\n\nThere is a statistically significant increase in donation probability when going from 1:1 to 2:1 or 1:1 to 3:1, but no additional benefit from increasing the match beyond 2:1.\nThis suggests that while some increase in match generosity can motivate donors, there’s a point of diminishing psychological returns.\nIn practical terms: a 2:1 match is persuasive; a 3:1 match doesn’t move the needle any further.\n\n\n\nRegression: Match Ratio Impact on Donation Likelihood\nTo assess whether larger match ratios (e.g., 2:1 or 3:1) increased the probability of donation compared to a 1:1 match, I ran a linear regression using dummy variables: ratio1, ratio2, and ratio3.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\n# Filter to treatment group only\ndf_treated = df[df[\"treatment\"] == 1].copy()\n\n# Clean and define ratio indicators\ndf_treated['ratio_clean'] = pd.to_numeric(df_treated['ratio'], errors='coerce')\ndf_treated['ratio1'] = (df_treated['ratio_clean'] == 1).astype(int)\ndf_treated['ratio2'] = (df_treated['ratio_clean'] == 2).astype(int)\ndf_treated['ratio3'] = (df_treated['ratio_clean'] == 3).astype(int)\n\n# Run regression within treatment group\nmodel = smf.ols(\"gave ~  ratio2 + ratio3\", data=df_treated).fit()\n\n# Extract summary for display\nsummary_df = pd.DataFrame({\n    'Coefficient': model.params.round(6),\n    'Std. Error': model.bse.round(6),\n    'P-value': model.pvalues.round(4),\n})\n\n# Keep only match ratio rows\nsummary_df.loc[['Intercept', 'ratio2', 'ratio3']]\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\nP-value\n\n\n\n\nIntercept\n0.020749\n0.001391\n0.0000\n\n\nratio2\n0.001884\n0.001968\n0.3383\n\n\nratio3\n0.001984\n0.001968\n0.3133\n\n\n\n\n\n\n\n\n\n\n\n\nRegression Interpretation\nI ran a linear regression within the treatment group to assess whether higher match ratios (2:1, 3:1) significantly increased the probability of donation compared to a 1:1 match.\nThe 1:1 match group had a baseline donation rate of approximately 2.07%. The 2:1 and 3:1 groups had slightly higher donation rates (~2.26% and ~2.27%), but the differences were not statistically significant.\nThis aligns with the paper’s findings and suggests that while offering a match matters, increasing the match ratio beyond 1:1 does not lead to a meaningful increase in donation behavior.\n\n\n\n\n\n\n\n\n\nCode\n# From previous regression: Intercept is 1:1, ratio2 and ratio3 are relative to 1:1\nintercept = 0.020749\ncoef_2_1 = 0.001884\ncoef_3_1 = 0.001984\n\n# Differences from regression coefficients\ndiff_2_1_minus_1_1 = coef_2_1\ndiff_3_1_minus_2_1 = coef_3_1 - coef_2_1\n\n# Differences from raw data\nmean_1_1 = df_treated[df_treated[\"ratio_clean\"] == 1][\"gave\"].mean()\nmean_2_1 = df_treated[df_treated[\"ratio_clean\"] == 2][\"gave\"].mean()\nmean_3_1 = df_treated[df_treated[\"ratio_clean\"] == 3][\"gave\"].mean()\n\nraw_diff_2_1_minus_1_1 = mean_2_1 - mean_1_1\nraw_diff_3_1_minus_2_1 = mean_3_1 - mean_2_1\n\n# Create a comparison DataFrame\ndiff_df = pd.DataFrame({\n    \"Method\": [\"Raw Data\", \"Regression Coefficients\"],\n    \"2:1 vs 1:1\": [raw_diff_2_1_minus_1_1, diff_2_1_minus_1_1],\n    \"3:1 vs 2:1\": [raw_diff_3_1_minus_2_1, diff_3_1_minus_2_1]\n}).round(4)\n\ndiff_df\n\n\n\n\n\n\n\n\n\nMethod\n2:1 vs 1:1\n3:1 vs 2:1\n\n\n\n\n0\nRaw Data\n0.0019\n0.0001\n\n\n1\nRegression Coefficients\n0.0019\n0.0001\n\n\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nI ran a t-test and a bivariate linear regression to compare the average donation amounts between treatment and control groups.\nOn average, the treatment group gave $0.15 more than the control group. However, the difference was not statistically significant at the 5% level (p ≈ 0.055–0.063), though it would be considered significant at a more lenient 10% threshold.\nThis suggests that while there may be a positive effect of treatment on the amount given, the evidence is not strong enough to confirm it confidently. The effect on whether someone gives is clearer than on how much they give, consistent with findings in Karlan & List (2007)\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Drop missing if needed (likely none for 'treatment' or 'amount')\ndf = df.dropna(subset=[\"amount\", \"treatment\"])\n\n# T-test\namount_treated = df[df[\"treatment\"] == 1][\"amount\"]\namount_control = df[df[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val = ttest_ind(amount_treated, amount_control, equal_var=False)\n\n# Linear regression\nmodel = smf.ols(\"amount ~ treatment\", data=df).fit()\n\n# Summary Table\nsummary_df = pd.DataFrame({\n    \"Control Mean\": [amount_control.mean()],\n    \"Treatment Mean\": [amount_treated.mean()],\n    \"Difference (T-test)\": [amount_treated.mean() - amount_control.mean()],\n    \"T-statistic\": [round(t_stat, 4)],\n    \"T-test P-value\": [round(p_val, 4)],\n    \"Regression Coefficient\": [model.params[\"treatment\"]],\n    \"Regression P-value\": [model.pvalues[\"treatment\"]]\n}).round(4)\n\nsummary_df\n\n\n\n\n\n\n\n\n\nControl Mean\nTreatment Mean\nDifference (T-test)\nT-statistic\nT-test P-value\nRegression Coefficient\nRegression P-value\n\n\n\n\n0\n0.8133\n0.9669\n0.1536\n1.9183\n0.0551\n0.1536\n0.0628\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\nI restricted the analysis to only those individuals who made a donation (gave == 1) and ran a t-test and bivariate regression to compare donation amounts between treatment and control groups.\nInterestingly, the average amount given was actually slightly lower in the treatment group than in the control group (by approximately $1.67), but this difference was not statistically significant (p ≈ 0.56).\nThese results suggest that while the treatment increased the likelihood of giving, it did not increase the amount given among those who chose to donate. In fact, it may have had a weak negative effect — though we cannot confidently conclude that from this data.\nThis supports the paper’s claim that matching offers are most effective at increasing participation (extensive margin) rather than increasing the donation amount (intensive margin).\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Subset to people who donated\ndf_donors = df[df[\"gave\"] == 1].copy()\n\n# Drop NAs just in case\ndf_donors = df_donors.dropna(subset=[\"amount\", \"treatment\"])\n\n# T-test\namount_treated = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\namount_control = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val = ttest_ind(amount_treated, amount_control, equal_var=False)\n\n# Regression\nmodel = smf.ols(\"amount ~ treatment\", data=df_donors).fit()\n\n# Summarize results\nsummary_df = pd.DataFrame({\n    \"Control Mean\": [amount_control.mean()],\n    \"Treatment Mean\": [amount_treated.mean()],\n    \"Difference (T-test)\": [amount_treated.mean() - amount_control.mean()],\n    \"T-statistic\": [round(t_stat, 4)],\n    \"T-test P-value\": [round(p_val, 4)],\n    \"Regression Coefficient\": [model.params[\"treatment\"]],\n    \"Regression P-value\": [model.pvalues[\"treatment\"]]\n}).round(4)\n\nsummary_df\n\n\n\n\n\n\n\n\n\nControl Mean\nTreatment Mean\nDifference (T-test)\nT-statistic\nT-test P-value\nRegression Coefficient\nRegression P-value\n\n\n\n\n0\n45.540298\n43.871899\n-1.6684\n-0.5846\n0.559\n-1.6684\n0.5615\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoes the Treatment Coefficient Have a Causal Interpretation?\nAt first glance, it might seem that the treatment coefficient in this regression could be interpreted causally, since treatment was randomly assigned. However, this specific analysis is conducted only among individuals who made a donation (i.e., conditional on gave == 1). This changes things substantially.\nWhen we condition on donation — an outcome that is itself affected by treatment — we introduce what’s known as post-treatment bias or selection bias. In other words, we are no longer comparing a truly randomized sample. Instead, we’re comparing individuals who selected into donating, and treatment could have affected that selection process.\nThis means that the regression coefficient does not represent the causal effect of treatment on donation amounts. Instead, it tells us about the association between treatment and donation size among people who already decided to give. Importantly, those people may differ across treatment and control in unobserved ways (e.g., motivation or baseline generosity), and these differences are no longer randomly distributed.\nThis is why, in causal inference, we avoid conditioning on variables that lie downstream of the treatment. The causal effect of treatment on the probability of donating (extensive margin) can still be validly estimated using the full dataset. However, once we filter to a subset like gave == 1, we are no longer leveraging the power of randomization to estimate a clean treatment effect.\n\n\nKey Takeaway\nThe observed difference in donation amount among donors is interesting and worth reporting — but it should not be interpreted as causal. It simply reflects how donation amounts vary within a post-treatment-selected group, not how treatment caused those donation amounts to differ.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Filter: only people who donated\ndf_donors = df[df[\"gave\"] == 1]\n\n# Split by group\ntreatment_group = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\ncontrol_group = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\n\n# Means\nmean_treat = treatment_group.mean()\nmean_control = control_group.mean()\n\n# Plot\nfig, axs = plt.subplots(2, 1, figsize=(8, 4), sharey=True)\n\n# Control group histogram\naxs[0].hist(control_group, bins=30, color='#add8e6', edgecolor='black')\naxs[0].axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_control:.2f}\")\naxs[0].set_title(\"Control Group\")\naxs[0].set_xlabel(\"Donation Amount\")\naxs[0].set_ylabel(\"Number of Donors\")\naxs[0].legend()\n\n# Treatment group histogram\naxs[1].hist(treatment_group, bins=30, color='#00008b', edgecolor='black')\naxs[1].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_treat:.2f}\")\naxs[1].set_title(\"Treatment Group\")\naxs[1].set_xlabel(\"Donation Amount\")\naxs[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDonation Amounts (Conditional on Giving) by Treatment Status\n\n\n\n\n\n\n\nThe histograms of donation amounts (conditional on giving) reveal that while both groups exhibit right-skewed giving patterns, the treatment group gave slightly less on average than the control group. This confirms earlier regression and t-test findings, where the treatment group’s mean donation was ~$1.67 lower and not statistically significant. Thus, the treatment appears to have increased participation, but not the amount given per donor."
  },
  {
    "objectID": "Homework1/hw1_questions.html#simulation-experiment",
    "href": "Homework1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic works, this section uses simulation to demonstrate two core statistical concepts:\n\nThe Law of Large Numbers (LLN)\n\nThe Central Limit Theorem (CLT)\n\nSuppose the true distribution of respondents who do not receive a charitable donation match is modeled as a Bernoulli distribution with probability: p = 0.018\nThis means 1.8% of people in the control group are expected to donate.\nFurther, suppose that the distribution of respondents who do receive a charitable donation match of any size is also Bernoulli, with: p = 0.022\nThis reflects a 2.2% donation probability in the treatment group. These values reflect the observed response rates in the experiment.\nThe following simulations explore: - How repeated sampling stabilizes around the true treatment effect (LLN) - How the sampling distribution of mean differences becomes approximately normal (CLT)\n\nLaw of Large Numbers\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set the true probabilities (based on your data)\np_control = 0.0179  # 1.79% donation rate\np_treatment = 0.0220  # 2.20% donation rate\n\n# Simulate 10,000 differences in donation rates\nnp.random.seed(42)\nn = 10000\ncontrol_draws = np.random.binomial(1, p_control, n)\ntreatment_draws = np.random.binomial(1, p_treatment, n)\n\ndiffs = treatment_draws - control_draws\n\n# Cumulative average of the differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)\n\n# Plot\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative Avg. Difference\", linewidth=1.5)\nplt.axhline(p_treatment - p_control, color='red', linestyle='--', label=\"True Difference\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Avg. (Treatment - Control)\")\nplt.title(\"Law of Large Numbers in Action\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nLaw of Large Numbers: Cumulative Average of Donation Rate Differences\n\n\n\n\n\n\n\nThe plot shows how the cumulative average difference in donation rates between the simulated treatment and control groups stabilizes over time. Initially, there is substantial fluctuation, but as the number of simulations increases, the cumulative average converges to the true difference in population means (approximately 0.0041).\nThis visualization demonstrates the Law of Large Numbers: as sample size increases, the average of the observed differences converges to the expected (true) value. In the context of this experiment, it reinforces that large-scale testing (like Karlan & List’s 50,000+ mailings) provides stable and trustworthy estimates of treatment effects.\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set true probabilities\np_control = 0.0179\np_treatment = 0.0220\ntrue_diff = p_treatment - p_control\n\n# Set sample sizes\nsample_sizes = [50, 200, 500, 1000]\n\n# Setup for plotting\nfig, axs = plt.subplots(4, 1, figsize=(8, 10))\naxs = axs.flatten()\n\nnp.random.seed(42)\n\n# Loop over each sample size\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(1000):\n        c_sample = np.random.binomial(1, p_control, n)\n        t_sample = np.random.binomial(1, p_treatment, n)\n        diff = t_sample.mean() - c_sample.mean()\n        diffs.append(diff)\n\n    axs[i].hist(diffs, bins=30, color='#add8e6', edgecolor='black')\n    axs[i].axvline(true_diff, color='red', linestyle='--', linewidth=2, label='True Diff')\n    axs[i].axvline(0, color='black', linestyle=':', linewidth=1, label='Zero')\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Mean Difference\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nCentral Limit Theorem: Distribution of Mean Differences Across Sample Sizes\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem: Interpretation\nThese four histograms show the distribution of average donation rate differences between treatment and control groups, across 1,000 simulations, for sample sizes of 50, 200, 500, and 1000.\n\nAt n = 50, the distribution is wide and somewhat lumpy — sampling variation dominates, and zero is often near the center.\nAs sample size increases, the distribution becomes tighter and more symmetric.\nBy n = 1000, the distribution of differences is sharply centered around the true difference, and zero is clearly in the tail.\n\nThis illustrates the Central Limit Theorem: with large enough samples, the distribution of sample means (or mean differences) is approximately normal, even if the underlying data is binary.\nIn this context, it shows how small effects can be confidently detected with large sample sizes, as demonstrated in Karlan & List’s field experiment."
  },
  {
    "objectID": "Homework1/hw1_questions.html#interpretation-3",
    "href": "Homework1/hw1_questions.html#interpretation-3",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Interpretation",
    "text": "Interpretation\nI restricted the analysis to only those individuals who made a donation (gave == 1) and ran a t-test and bivariate regression to compare donation amounts between treatment and control groups.\nInterestingly, the average amount given was actually slightly lower in the treatment group than in the control group (by ~$1.67), but this difference was not statistically significant (p ≈ 0.56).\nThese results suggest that while the treatment increased the likelihood of giving, it did not increase the amount given among those who chose to donate. In fact, it may have had a weak negative effect — though we cannot confidently conclude that from this data.\nThis supports the paper’s claim that matching offers are most effective at increasing participation (extensive margin) rather than increasing the donation amount (intensive margin).\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Subset to people who donated\ndf_donors = df[df[\"gave\"] == 1].copy()\n\n# Drop NAs just in case\ndf_donors = df_donors.dropna(subset=[\"amount\", \"treatment\"])\n\n# T-test\namount_treated = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\namount_control = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val = ttest_ind(amount_treated, amount_control, equal_var=False)\n\n# Regression\nmodel = smf.ols(\"amount ~ treatment\", data=df_donors).fit()\n\n# Summarize results\nsummary_df = pd.DataFrame({\n    \"Control Mean\": [amount_control.mean()],\n    \"Treatment Mean\": [amount_treated.mean()],\n    \"Difference (T-test)\": [amount_treated.mean() - amount_control.mean()],\n    \"T-statistic\": [round(t_stat, 4)],\n    \"T-test P-value\": [round(p_val, 4)],\n    \"Regression Coefficient\": [model.params[\"treatment\"]],\n    \"Regression P-value\": [model.pvalues[\"treatment\"]]\n}).round(4)\n\nsummary_df\n\n\n\n\n\n\n\n\n\nControl Mean\nTreatment Mean\nDifference (T-test)\nT-statistic\nT-test P-value\nRegression Coefficient\nRegression P-value\n\n\n\n\n0\n45.540298\n43.871899\n-1.6684\n-0.5846\n0.559\n-1.6684\n0.5615"
  },
  {
    "objectID": "Homework1/hw1_questions.html#does-the-treatment-coefficient-have-a-causal-interpretation",
    "href": "Homework1/hw1_questions.html#does-the-treatment-coefficient-have-a-causal-interpretation",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Does the treatment coefficient have a causal interpretation?",
    "text": "Does the treatment coefficient have a causal interpretation?\nYes — because treatment was randomly assigned, the coefficient reflects a causal effect of treatment on donation amount, conditional on giving\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Filter: only people who donated\ndf_donors = df[df[\"gave\"] == 1]\n\n# Split by group\ntreatment_group = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\ncontrol_group = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\n\n# Means\nmean_treat = treatment_group.mean()\nmean_control = control_group.mean()\n\n# Plot\nfig, axs = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\n# Control group histogram\naxs[0].hist(control_group, bins=30, color='skyblue', edgecolor='black')\naxs[0].axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_control:.2f}\")\naxs[0].set_title(\"Control Group\")\naxs[0].set_xlabel(\"Donation Amount\")\naxs[0].set_ylabel(\"Number of Donors\")\naxs[0].legend()\n\n# Treatment group histogram\naxs[1].hist(treatment_group, bins=30, color='lightgreen', edgecolor='black')\naxs[1].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_treat:.2f}\")\naxs[1].set_title(\"Treatment Group\")\naxs[1].set_xlabel(\"Donation Amount\")\naxs[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDonation Amounts (Conditional on Giving) by Treatment Status\n\n\n\n\nThe histograms of donation amounts (conditional on giving) reveal that while both groups exhibit right-skewed giving patterns, the treatment group gave slightly less on average than the control group. This confirms earlier regression and t-test findings, where the treatment group’s mean donation was ~$1.67 lower and not statistically significant. Thus, the treatment appears to have increased participation, but not the amount given per donor."
  },
  {
    "objectID": "Homework1/hw1_questions.html#interpretation-4",
    "href": "Homework1/hw1_questions.html#interpretation-4",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Interpretation",
    "text": "Interpretation\nThese four histograms show the distribution of average donation rate differences between treatment and control groups, across 1000 simulations, for sample sizes of 50, 200, 500, and 1000.\nAt n = 50, the distribution is wide and somewhat lumpy — sampling variation dominates, and zero is often near the center.\nAs sample size increases, the distribution becomes tighter and more symmetric.\nBy n = 1000, the distribution of differences is sharply centered around the true difference, and zero is clearly in the tail.\nThis illustrates the Central Limit Theorem: with large enough samples, the distribution of sample means (or mean differences) is approximately normal, even if the underlying data is binary. In this context, it shows how small effects can be confidently detected with large sample sizes, as seen in Karlan & List’s field experiment."
  },
  {
    "objectID": "Homework1/hw1_questions.html#balance-test",
    "href": "Homework1/hw1_questions.html#balance-test",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Balance Test",
    "text": "Balance Test\nAs an ad hoc test of the randomization mechanism, I conducted a series of comparisons between the treatment and control groups to assess whether they differ significantly on key pre-treatment characteristics. This helps confirm whether the random assignment of treatment was implemented correctly.\nTo verify that treatment was randomly assigned, I tested whether the following pre-treatment variables differed between the two groups:\n\nmrm2: Months since last donation\n\nfreq: Number of prior donations\n\nfemale: Gender indicator (1 = female)\n\nhpa: Highest previous contribution\n\nFor each variable, I conducted both:\n\nA two-sample t-test, and\n\nA simple linear regression of the form:\n\n\nResult\nNone of the tested variables show statistically significant differences between the treatment and control groups at the 95% confidence level. The t-test and regression results are consistent, confirming that randomization appears to have worked as intended.\nThis balance check serves the same purpose as Table 1 in the original paper: it shows that treatment assignment was not systematically related to baseline characteristics. This supports the causal interpretation of treatment effects on outcomes later in the analysis.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load the .dta file (if not already in CSV)\ndta_file = 'karlan_list_2007.dta'\ndf = pd.read_stata(dta_file)\n\n# Select variables to test for balance\nvars_to_test = ['mrm2', 'freq', 'female', 'hpa']\ndf_clean = df[['treatment'] + vars_to_test].dropna()\n\n# Initialize lists for storing results\nt_test_results = []\nregression_results = []\n\nfor var in vars_to_test:\n    # Separate treatment and control groups\n    treat_group = df_clean[df_clean['treatment'] == 1][var]\n    control_group = df_clean[df_clean['treatment'] == 0][var]\n\n    # Two-sample t-test (Welch's t-test)\n    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)\n\n    # Simple linear regression\n    model = smf.ols(f\"{var} ~ treatment\", data=df_clean).fit()\n    coef = model.params['treatment']\n    reg_pval = model.pvalues['treatment']\n\n    # Store nicely formatted results\n    t_test_results.append({\n        \"Variable\": var,\n        \"T-test p-value\": round(t_pval, 4),\n        \"Significant (T-test)\": \"Yes\" if t_pval &lt; 0.05 else \"No\"\n    })\n\n    regression_results.append({\n        \"Variable\": var,\n        \"Regression coef\": round(coef, 4),\n        \"Regression p-value\": round(reg_pval, 4),\n        \"Significant (Regression)\": \"Yes\" if reg_pval &lt; 0.05 else \"No\"\n    })\n\n# Create DataFrames\nt_df = pd.DataFrame(t_test_results)\nr_df = pd.DataFrame(regression_results)\n\n# Print clean tables\nprint(\"=== T-Test Results ===\")\nprint(t_df.to_string(index=False))\n\nprint(\"\\n=== Linear Regression Results ===\")\nprint(r_df.to_string(index=False))\n\n\n=== T-Test Results ===\nVariable  T-test p-value Significant (T-test)\n    mrm2          0.9391                   No\n    freq          0.9524                   No\n  female          0.0786                   No\n     hpa          0.3132                   No\n\n=== Linear Regression Results ===\nVariable  Regression coef  Regression p-value Significant (Regression)\n    mrm2           0.0088              0.9391                       No\n    freq          -0.0066              0.9524                       No\n  female          -0.0076              0.0778                       No\n     hpa           0.6635              0.3274                       No"
  },
  {
    "objectID": "Homework2/hw2_questions.html",
    "href": "Homework2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\n\n# Load Blueprinty dataset\ndf_blueprinty = pd.read_csv(\"blueprinty.csv\")\n\n# Display first few rows\ndf_blueprinty.head()\n\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo assess whether firms using Blueprinty’s software tend to receive more patents, we compare both the distribution and average number of patents between customers and non-customers.\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# palette = {0: \"#4C72B0\", 1: \"#DD8452\"}\n# Plot histograms by customer status\nplt.figure(figsize=(8, 6))\nsns.histplot(data=df_blueprinty, x=\"patents\", hue=\"iscustomer\", multiple=\"stack\", palette=[\"#4C72B0\", \"#DD8452\"], bins=15)\nplt.xlabel(\"Number of Patents (last 5 years)\")\nplt.ylabel(\"Number of Firms\")\nplt.title(\"Distribution of Patents by Customer Status\")\nplt.legend(title=\"Is Customer\", labels=[\"No\", \"Yes\"])\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nHistogram of Patents Awarded by Customer Status\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Compare average number of patents by customer status\ndf_blueprinty.groupby(\"iscustomer\")[\"patents\"].mean().rename({0: \"Non-customer\", 1: \"Customer\"})\n\n\niscustomer\nNon-customer    3.473013\nCustomer        4.133056\nName: patents, dtype: float64\n\n\n\n\n\nWe observe that customers of Blueprinty tend to have a higher average number of patents compared to non-customers. The histogram shows a greater concentration of higher patent counts among customers. However, this is a descriptive comparison** — it does not yet account for other variables like firm age or region.\nIn the next step, we will model the number of patents more formally using Poisson regression, both via MLE and built-in methods.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\nWe now compare two additional variables — region and age — to see how they differ between Blueprinty customers and non-customers.\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# palette = {0: \"#4C72B0\", 1: \"#DD8452\"}\n\n# Bar plot of region by customer status\nplt.figure(figsize=(8, 6))\nsns.countplot(data=df_blueprinty, x=\"region\", hue=\"iscustomer\", palette=[\"#4C72B0\", \"#DD8452\"])\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Number of Firms\")\nplt.legend(title=\"Is Customer\", labels=[\"Yes\", \"No\"])\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFigure: Region Distribution by Customer Status\n\n\n\n\nThe first figure shows the distribution of firms by region, split between Blueprinty customers and non-customers. We observe that:\n\nThe Northeast region has a substantially higher share of Blueprinty customers than other regions.\nIn contrast, regions like the Midwest, Southwest, and Northwest are dominated by non-customers.\nThis suggests that Blueprinty’s customer base is not randomly distributed geographically and region may be associated with software adoption.\n\n\n\n\nThe boxplot above compares the distribution of firm ages between Blueprinty customers and non-customers.\n\n\nCode\n# Boxplot of age by customer status\n# Boxplot of age by customer status\n\n# palette = {0: \"#4C72B0\", 1: \"#DD8452\"}\n\nplt.figure(figsize=(8, 6))\nsns.boxplot(\n    data=df_blueprinty,\n    x=\"iscustomer\",\n    y=\"age\",\n    hue=\"iscustomer\",  # assign hue\n    palette=[\"#4C72B0\", \"#DD8452\"],\n    legend=False,\n    showfliers=False\n)\nplt.xticks([0, 1], [\"Non-Customer\", \"Customer\"])\nplt.title(\"Firm Age by Customer Status\")\nplt.xlabel(\"Customer Status\")\nplt.ylabel(\"Firm Age (Years)\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFigure: Firm Age Distribution by Customer Status\n\n\n\n\n\nBoth groups have similar median ages, around 25–27 years.\nThe spread and interquartile range are also comparable, suggesting no substantial difference in age distribution between the two groups.\nThis implies that any difference in patent output is unlikely to be driven by firm age alone and supports the need to control for age in the Poisson regression model.\n\n#| label: summary-age-region #| output: true\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf_blueprinty.groupby(\"iscustomer\")[\"region\"].value_counts(normalize=True).unstack()\ndf_blueprinty.groupby(\"iscustomer\")[\"age\"].mean().round(2)\n\n\niscustomer\n0    26.1\n1    26.9\nName: age, dtype: float64\n\n\n\n\n\nThe second figure compares the distribution of firm ages by customer status using boxplots:\n\nCustomers and non-customers appear to have similar age distributions, though customers are slightly younger on average.\nBoth groups contain a mix of newer and older firms, but non-customers show slightly more outliers on the higher end.\n\nThese patterns imply that both region and firm age should be included as control variables in our regression models to better isolate the effect of Blueprinty software usage on patent output.The second figure compares the distribution of firm ages by customer status using boxplots:\n\nCustomers and non-customers appear to have similar age distributions, though customers are slightly younger on average.\nBoth groups contain a mix of newer and older firms, but non-customers show slightly more outliers on the higher end.\n\nThese patterns imply that both region and firm age should be included as control variables in our regression models to better isolate the effect of Blueprinty software usage on patent output.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\n\n\nSince our outcome variable of interest (patents) consists of non-negative integer counts over a fixed time window, it is appropriate to model it using a Poisson distribution.\nLet \\(Y_i\\) be the number of patents awarded to firm \\(i\\), and assume:\n\\[\nY_i \\sim \\text{Poisson}(\\lambda_i)\n\\]\nThe probability mass function is:\n\\[\nf(Y_i \\mid \\lambda_i) = \\frac{e^{-\\lambda_i} \\lambda_i^{Y_i}}{Y_i!}\n\\]\nAssuming independence across firms, the likelihood function for the full sample is:\n\\[\nL(\\boldsymbol{\\lambda}) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda_i} \\lambda_i^{Y_i}}{Y_i!}\n\\]\nTaking logs gives the log-likelihood function:\n\\[\n\\log L(\\boldsymbol{\\lambda}) = \\sum_{i=1}^{n} \\left[ -\\lambda_i + Y_i \\log(\\lambda_i) - \\log(Y_i!) \\right]\n\\]\nIn regression form, we let:\n\\[\n\\lambda_i = \\exp(X_i \\boldsymbol{\\beta})\n\\]\nWe will now implement this likelihood in Python and estimate ( ) via Maximum Likelihood Estimation.\n\n\n\n\n\n\nTo build intuition about Maximum Likelihood Estimation (MLE) under a Poisson model, we visualize how the log-likelihood changes as a function of λ when the observed count ( Y = 3 ).\nThe peak of this curve represents the MLE, which for a scalar Poisson model corresponds to ( = Y ).\n\n\nCode\nimport numpy as np\nfrom scipy.special import gammaln\n\n# Define the Poisson log-likelihood function\ndef poisson_loglikelihood(lambd, Y):\n    if lambd &lt;= 0:\n        return -np.inf  # log-likelihood is undefined for non-positive lambda\n    return np.sum(-lambd + Y * np.log(lambd) - gammaln(Y + 1))\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.special import gammaln\n\n# Define scalar Poisson log-likelihood\ndef poisson_loglikelihood_scalar(lambd, y):\n    if lambd &lt;= 0:\n        return -np.inf\n    return y * np.log(lambd) - lambd - gammaln(y + 1)\n\n# Fixed observed Y\ny_obs = 3\n\n# λ values\nlambda_vals = np.linspace(0.1, 10, 300)\nlog_likelihoods = [poisson_loglikelihood_scalar(l, y_obs) for l in lambda_vals]\n\n# Plot\nplt.figure(figsize=(8, 6))\nplt.plot(lambda_vals, log_likelihoods, color=\"#D55E00\", linewidth=2)\nplt.axvline(x=y_obs, color=\"gray\", linestyle=\"--\", linewidth=1.5, label=f\"Y = {y_obs}\")\nplt.title(\"Poisson Log-Likelihood vs. λ\", fontsize=14)\nplt.xlabel(\"λ\", fontsize=12)\nplt.ylabel(\"Log-Likelihood\", fontsize=12)\nplt.legend()\nplt.grid(True, linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFigure: Poisson Log-Likelihood as a Function of λ When Y = 3\n\n\n\n\n\n\n\n\nTo derive the Maximum Likelihood Estimate (MLE) for a Poisson model, we start with the probability mass function:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nAssuming we observe ( n ) independent draws ( Y_1, Y_2, , Y_n ), the log-likelihood function is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^n \\left[ Y_i \\log(\\lambda) - \\lambda - \\log(Y_i!) \\right]\n\\]\nWe now take the first derivative with respect to ( ) and set it equal to zero to find the MLE:\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^n \\left( \\frac{Y_i}{\\lambda} - 1 \\right)\n\\]\nSimplifying:\n\\[\n\\frac{1}{\\lambda} \\sum_{i=1}^n Y_i - n = 0\n\\]\nSolving for ( ):\n\\[\n\\frac{1}{\\lambda} \\sum Y_i = n \\quad \\Rightarrow \\quad \\sum Y_i = n\\lambda \\quad \\Rightarrow \\quad \\lambda = \\frac{1}{n} \\sum Y_i = \\bar{Y}\n\\]\n\n\n\n\n\n\nThe MLE for \\(\\lambda\\) is the sample mean:\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n\\]\nThis makes intuitive sense because the mean of a Poisson distribution is equal to \\(\\lambda\\), and the sample mean is the natural estimator of the population mean.\n\n\n\nCode\nfrom scipy import optimize\nfrom scipy.special import gammaln\nimport numpy as np\n\n# Define Y (observed patent counts)\nY = df_blueprinty[\"patents\"].values\n\n# Define scalar log-likelihood inline\npoisson_loglikelihood = lambda lambd, Y: np.sum(Y * np.log(lambd) - lambd - gammaln(Y + 1))\n\n# Negative log-likelihood for optimizer\nneg_loglikelihood = lambda lambd: -poisson_loglikelihood(lambd[0], Y)\n\n# Optimize\nresult = optimize.minimize(neg_loglikelihood, x0=[1.0], bounds=[(1e-6, None)])\n\n# Extract MLE\nlambda_mle = result.x[0]\nlambda_mle\n\n\n3.684666485763343\n\n\n\n\n\n\n\nCode\n# Compare the MLE with the sample mean\ndf_blueprinty[\"patents\"].mean()\n\n\n3.6846666666666668\n\n\n\n\n\nAs expected under the Poisson model, the MLE of λ is equal to the sample mean of the observed patent counts:\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n\\]\nThis confirms the theoretical result that the mean of a Poisson distribution is both its expectation and the MLE for its rate parameter.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty. \n\n\n\nCode\nimport numpy as np\nfrom scipy.special import gammaln\n\n# Define the Poisson log-likelihood function\ndef poisson_loglikelihood_regression(beta, X, y):\n    lambda_ = np.exp(X @ beta)\n    return np.sum(y * np.log(lambda_) - lambda_ - gammaln(y + 1))\n\n# Prepare data\ndf_blueprinty[\"intercept\"] = 1\nX = df_blueprinty[[\"intercept\", \"age\", \"iscustomer\"]].values\ny = df_blueprinty[\"patents\"].values\n\n# Initial guess for beta\nbeta_init = np.zeros(X.shape[1])\n\n# Compute log-likelihood\nlog_likelihood = poisson_loglikelihood_regression(beta_init, X, y)\n\n# Display result\n# print(f\"Log-likelihood at initial beta (zeros): {log_likelihood:.4f}\")\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\n# One-hot encode region and fix age/age_squared\nregion_dummies = pd.get_dummies(df_blueprinty[\"region\"], drop_first=True)\nage = df_blueprinty[\"age\"]\n\nX = pd.concat([\n    pd.Series(1, index=age.index, name=\"intercept\"),\n    age.rename(\"age\"),\n    (age ** 2 / 100).rename(\"age_squared\"),  # scaled\n    region_dummies,\n    df_blueprinty[\"iscustomer\"]\n], axis=1).astype(float)\n\ny = df_blueprinty[\"patents\"].values\nX_matrix = X.to_numpy()\n\n# Poisson negative log-likelihood\ndef neg_loglikelihood_beta(beta, X, y):\n    lambda_ = np.exp(X @ beta)\n    return -np.sum(y * np.log(lambda_) - lambda_ - gammaln(y + 1))\n\n# Run optimizer\nbeta_init = np.zeros(X_matrix.shape[1])\nresult = minimize(neg_loglikelihood_beta, beta_init, args=(X_matrix, y), method=\"BFGS\")\nbeta_hat = result.x\n\n# Hessian and standard errors\ndef hessian_poisson(beta, X):\n    lambda_ = np.exp(X @ beta)\n    W = np.diag(lambda_)\n    return X.T @ W @ X\n\nH = hessian_poisson(beta_hat, X_matrix)\ncov_matrix = np.linalg.inv(H)  # should work now\nstandard_errors = np.sqrt(np.diag(cov_matrix))\n\n# Output table\ncoef_table = pd.DataFrame({\n    \"Coefficient\": beta_hat,\n    \"Std. Error\": standard_errors\n}, index=X.columns).round(4)\n\ncoef_table\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.5089\n0.1832\n\n\nage\n0.1486\n0.0139\n\n\nage_squared\n-0.2970\n0.0258\n\n\nNortheast\n0.0292\n0.0436\n\n\nNorthwest\n-0.0176\n0.0538\n\n\nSouth\n0.0566\n0.0527\n\n\nSouthwest\n0.0506\n0.0472\n\n\niscustomer\n0.2076\n0.0309\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport statsmodels.api as sm\nimport pandas as pd\n\n# Rebuild the design matrix with correct naming and scaling\nregion_dummies = pd.get_dummies(df_blueprinty[\"region\"], drop_first=True)\nage = df_blueprinty[\"age\"]\n\nX_glm = pd.concat([\n    pd.Series(1, index=age.index, name=\"intercept\"),\n    age.rename(\"age\"),\n    (age ** 2 / 100).rename(\"age_squared\"),\n    region_dummies,\n    df_blueprinty[\"iscustomer\"]\n], axis=1).astype(float)\n\ny_glm = df_blueprinty[\"patents\"]\n\n# Fit model using statsmodels GLM with Poisson family\nmodel = sm.GLM(y_glm, X_glm, family=sm.families.Poisson())\nresults = model.fit()\n\n# Create results table\nglm_table = pd.DataFrame({\n    \"GLM Coefficient\": results.params,\n    \"GLM Std. Error\": results.bse\n}).round(4)\n\nglm_table\n\n\n\n\n\n\n\n\n\nGLM Coefficient\nGLM Std. Error\n\n\n\n\nintercept\n-0.5089\n0.1832\n\n\nage\n0.1486\n0.0139\n\n\nage_squared\n-0.2970\n0.0258\n\n\nNortheast\n0.0292\n0.0436\n\n\nNorthwest\n-0.0176\n0.0538\n\n\nSouth\n0.0566\n0.0527\n\n\nSouthwest\n0.0506\n0.0472\n\n\niscustomer\n0.2076\n0.0309\n\n\n\n\n\n\n\ntodo: Interpret the results.\n\n\n\nThe results from the built-in Poisson regression model (statsmodels.GLM) closely match those obtained from our custom MLE implementation. This consistency confirms the correctness of our estimation procedure.\nKey takeaways:\n\niscustomer: The coefficient is 0.2076, which implies that being a Blueprinty customer is associated with a 21% increase in expected patent count, holding other variables constant. This supports the company’s claim that their customers tend to be more successful in securing patents.\nage and age_squared: The positive coefficient on age and negative coefficient on age_squared indicate a nonlinear relationship: the expected number of patents increases with age at first, but eventually levels off or declines slightly — a classic concave curve.\nregion dummies: Coefficients on regional variables are relatively small, suggesting modest variation in patent rates across regions compared to the base group (the dropped region).\nintercept: The intercept (-0.5089) reflects the baseline log expected count of patents for a firm with all other predictors at zero (not very interpretable on its own, but standard in GLMs).\n\nOverall, the model suggests that Blueprinty customers tend to have higher patent counts, and firm age plays a significant but diminishing role in patent output. The regional effects are comparatively minor.\n\n\n\nCode\nimport numpy as np\n\n# Copy design matrix and create two versions\nX_0 = X.copy()\nX_1 = X.copy()\nX_0[\"iscustomer\"] = 0\nX_1[\"iscustomer\"] = 1\n\n# Convert to NumPy arrays\nX0_matrix = X_0.to_numpy()\nX1_matrix = X_1.to_numpy()\n\n# Predicted patent counts under both scenarios\ny_pred_0 = np.exp(X0_matrix @ beta_hat)\ny_pred_1 = np.exp(X1_matrix @ beta_hat)\n\n# Compute average treatment effect\navg_effect = np.mean(y_pred_1 - y_pred_0)\navg_effect\n\n\n0.7927623954445165\n\n\n\n\n\nUsing our estimated Poisson regression model, we predicted the number of patents each firm would receive under two hypothetical scenarios:\n\nScenario 1: None of the firms are Blueprinty customers\n\nScenario 2: All of the firms are Blueprinty customers\n\nThis means that, on average, using Blueprinty’s software is associated with an increase of approximately 0.79 patents per firm over the 5-year period, holding all else constant.\nThis approach provides an intuitive interpretation of the model’s estimated iscustomer coefficient on the original patent count scale, rather than in terms of logged outcomes or incidence rate ratios."
  },
  {
    "objectID": "Homework2/hw2_questions.html#blueprinty-case-study",
    "href": "Homework2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\n\n# Load Blueprinty dataset\ndf_blueprinty = pd.read_csv(\"blueprinty.csv\")\n\n# Display first few rows\ndf_blueprinty.head()\n\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo assess whether firms using Blueprinty’s software tend to receive more patents, we compare both the distribution and average number of patents between customers and non-customers.\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# palette = {0: \"#4C72B0\", 1: \"#DD8452\"}\n# Plot histograms by customer status\nplt.figure(figsize=(8, 6))\nsns.histplot(data=df_blueprinty, x=\"patents\", hue=\"iscustomer\", multiple=\"stack\", palette=[\"#4C72B0\", \"#DD8452\"], bins=15)\nplt.xlabel(\"Number of Patents (last 5 years)\")\nplt.ylabel(\"Number of Firms\")\nplt.title(\"Distribution of Patents by Customer Status\")\nplt.legend(title=\"Is Customer\", labels=[\"No\", \"Yes\"])\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nHistogram of Patents Awarded by Customer Status\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Compare average number of patents by customer status\ndf_blueprinty.groupby(\"iscustomer\")[\"patents\"].mean().rename({0: \"Non-customer\", 1: \"Customer\"})\n\n\niscustomer\nNon-customer    3.473013\nCustomer        4.133056\nName: patents, dtype: float64\n\n\n\n\n\nWe observe that customers of Blueprinty tend to have a higher average number of patents compared to non-customers. The histogram shows a greater concentration of higher patent counts among customers. However, this is a descriptive comparison** — it does not yet account for other variables like firm age or region.\nIn the next step, we will model the number of patents more formally using Poisson regression, both via MLE and built-in methods.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\nWe now compare two additional variables — region and age — to see how they differ between Blueprinty customers and non-customers.\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# palette = {0: \"#4C72B0\", 1: \"#DD8452\"}\n\n# Bar plot of region by customer status\nplt.figure(figsize=(8, 6))\nsns.countplot(data=df_blueprinty, x=\"region\", hue=\"iscustomer\", palette=[\"#4C72B0\", \"#DD8452\"])\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Number of Firms\")\nplt.legend(title=\"Is Customer\", labels=[\"Yes\", \"No\"])\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFigure: Region Distribution by Customer Status\n\n\n\n\nThe first figure shows the distribution of firms by region, split between Blueprinty customers and non-customers. We observe that:\n\nThe Northeast region has a substantially higher share of Blueprinty customers than other regions.\nIn contrast, regions like the Midwest, Southwest, and Northwest are dominated by non-customers.\nThis suggests that Blueprinty’s customer base is not randomly distributed geographically and region may be associated with software adoption.\n\n\n\n\nThe boxplot above compares the distribution of firm ages between Blueprinty customers and non-customers.\n\n\nCode\n# Boxplot of age by customer status\n# Boxplot of age by customer status\n\n# palette = {0: \"#4C72B0\", 1: \"#DD8452\"}\n\nplt.figure(figsize=(8, 6))\nsns.boxplot(\n    data=df_blueprinty,\n    x=\"iscustomer\",\n    y=\"age\",\n    hue=\"iscustomer\",  # assign hue\n    palette=[\"#4C72B0\", \"#DD8452\"],\n    legend=False,\n    showfliers=False\n)\nplt.xticks([0, 1], [\"Non-Customer\", \"Customer\"])\nplt.title(\"Firm Age by Customer Status\")\nplt.xlabel(\"Customer Status\")\nplt.ylabel(\"Firm Age (Years)\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFigure: Firm Age Distribution by Customer Status\n\n\n\n\n\nBoth groups have similar median ages, around 25–27 years.\nThe spread and interquartile range are also comparable, suggesting no substantial difference in age distribution between the two groups.\nThis implies that any difference in patent output is unlikely to be driven by firm age alone and supports the need to control for age in the Poisson regression model.\n\n#| label: summary-age-region #| output: true\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf_blueprinty.groupby(\"iscustomer\")[\"region\"].value_counts(normalize=True).unstack()\ndf_blueprinty.groupby(\"iscustomer\")[\"age\"].mean().round(2)\n\n\niscustomer\n0    26.1\n1    26.9\nName: age, dtype: float64\n\n\n\n\n\nThe second figure compares the distribution of firm ages by customer status using boxplots:\n\nCustomers and non-customers appear to have similar age distributions, though customers are slightly younger on average.\nBoth groups contain a mix of newer and older firms, but non-customers show slightly more outliers on the higher end.\n\nThese patterns imply that both region and firm age should be included as control variables in our regression models to better isolate the effect of Blueprinty software usage on patent output.The second figure compares the distribution of firm ages by customer status using boxplots:\n\nCustomers and non-customers appear to have similar age distributions, though customers are slightly younger on average.\nBoth groups contain a mix of newer and older firms, but non-customers show slightly more outliers on the higher end.\n\nThese patterns imply that both region and firm age should be included as control variables in our regression models to better isolate the effect of Blueprinty software usage on patent output.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\n\n\nSince our outcome variable of interest (patents) consists of non-negative integer counts over a fixed time window, it is appropriate to model it using a Poisson distribution.\nLet \\(Y_i\\) be the number of patents awarded to firm \\(i\\), and assume:\n\\[\nY_i \\sim \\text{Poisson}(\\lambda_i)\n\\]\nThe probability mass function is:\n\\[\nf(Y_i \\mid \\lambda_i) = \\frac{e^{-\\lambda_i} \\lambda_i^{Y_i}}{Y_i!}\n\\]\nAssuming independence across firms, the likelihood function for the full sample is:\n\\[\nL(\\boldsymbol{\\lambda}) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda_i} \\lambda_i^{Y_i}}{Y_i!}\n\\]\nTaking logs gives the log-likelihood function:\n\\[\n\\log L(\\boldsymbol{\\lambda}) = \\sum_{i=1}^{n} \\left[ -\\lambda_i + Y_i \\log(\\lambda_i) - \\log(Y_i!) \\right]\n\\]\nIn regression form, we let:\n\\[\n\\lambda_i = \\exp(X_i \\boldsymbol{\\beta})\n\\]\nWe will now implement this likelihood in Python and estimate ( ) via Maximum Likelihood Estimation.\n\n\n\n\n\n\nTo build intuition about Maximum Likelihood Estimation (MLE) under a Poisson model, we visualize how the log-likelihood changes as a function of λ when the observed count ( Y = 3 ).\nThe peak of this curve represents the MLE, which for a scalar Poisson model corresponds to ( = Y ).\n\n\nCode\nimport numpy as np\nfrom scipy.special import gammaln\n\n# Define the Poisson log-likelihood function\ndef poisson_loglikelihood(lambd, Y):\n    if lambd &lt;= 0:\n        return -np.inf  # log-likelihood is undefined for non-positive lambda\n    return np.sum(-lambd + Y * np.log(lambd) - gammaln(Y + 1))\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.special import gammaln\n\n# Define scalar Poisson log-likelihood\ndef poisson_loglikelihood_scalar(lambd, y):\n    if lambd &lt;= 0:\n        return -np.inf\n    return y * np.log(lambd) - lambd - gammaln(y + 1)\n\n# Fixed observed Y\ny_obs = 3\n\n# λ values\nlambda_vals = np.linspace(0.1, 10, 300)\nlog_likelihoods = [poisson_loglikelihood_scalar(l, y_obs) for l in lambda_vals]\n\n# Plot\nplt.figure(figsize=(8, 6))\nplt.plot(lambda_vals, log_likelihoods, color=\"#D55E00\", linewidth=2)\nplt.axvline(x=y_obs, color=\"gray\", linestyle=\"--\", linewidth=1.5, label=f\"Y = {y_obs}\")\nplt.title(\"Poisson Log-Likelihood vs. λ\", fontsize=14)\nplt.xlabel(\"λ\", fontsize=12)\nplt.ylabel(\"Log-Likelihood\", fontsize=12)\nplt.legend()\nplt.grid(True, linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFigure: Poisson Log-Likelihood as a Function of λ When Y = 3\n\n\n\n\n\n\n\n\nTo derive the Maximum Likelihood Estimate (MLE) for a Poisson model, we start with the probability mass function:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nAssuming we observe ( n ) independent draws ( Y_1, Y_2, , Y_n ), the log-likelihood function is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^n \\left[ Y_i \\log(\\lambda) - \\lambda - \\log(Y_i!) \\right]\n\\]\nWe now take the first derivative with respect to ( ) and set it equal to zero to find the MLE:\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^n \\left( \\frac{Y_i}{\\lambda} - 1 \\right)\n\\]\nSimplifying:\n\\[\n\\frac{1}{\\lambda} \\sum_{i=1}^n Y_i - n = 0\n\\]\nSolving for ( ):\n\\[\n\\frac{1}{\\lambda} \\sum Y_i = n \\quad \\Rightarrow \\quad \\sum Y_i = n\\lambda \\quad \\Rightarrow \\quad \\lambda = \\frac{1}{n} \\sum Y_i = \\bar{Y}\n\\]\n\n\n\n\n\n\nThe MLE for \\(\\lambda\\) is the sample mean:\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n\\]\nThis makes intuitive sense because the mean of a Poisson distribution is equal to \\(\\lambda\\), and the sample mean is the natural estimator of the population mean.\n\n\n\nCode\nfrom scipy import optimize\nfrom scipy.special import gammaln\nimport numpy as np\n\n# Define Y (observed patent counts)\nY = df_blueprinty[\"patents\"].values\n\n# Define scalar log-likelihood inline\npoisson_loglikelihood = lambda lambd, Y: np.sum(Y * np.log(lambd) - lambd - gammaln(Y + 1))\n\n# Negative log-likelihood for optimizer\nneg_loglikelihood = lambda lambd: -poisson_loglikelihood(lambd[0], Y)\n\n# Optimize\nresult = optimize.minimize(neg_loglikelihood, x0=[1.0], bounds=[(1e-6, None)])\n\n# Extract MLE\nlambda_mle = result.x[0]\nlambda_mle\n\n\n3.684666485763343\n\n\n\n\n\n\n\nCode\n# Compare the MLE with the sample mean\ndf_blueprinty[\"patents\"].mean()\n\n\n3.6846666666666668\n\n\n\n\n\nAs expected under the Poisson model, the MLE of λ is equal to the sample mean of the observed patent counts:\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n\\]\nThis confirms the theoretical result that the mean of a Poisson distribution is both its expectation and the MLE for its rate parameter.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty. \n\n\n\nCode\nimport numpy as np\nfrom scipy.special import gammaln\n\n# Define the Poisson log-likelihood function\ndef poisson_loglikelihood_regression(beta, X, y):\n    lambda_ = np.exp(X @ beta)\n    return np.sum(y * np.log(lambda_) - lambda_ - gammaln(y + 1))\n\n# Prepare data\ndf_blueprinty[\"intercept\"] = 1\nX = df_blueprinty[[\"intercept\", \"age\", \"iscustomer\"]].values\ny = df_blueprinty[\"patents\"].values\n\n# Initial guess for beta\nbeta_init = np.zeros(X.shape[1])\n\n# Compute log-likelihood\nlog_likelihood = poisson_loglikelihood_regression(beta_init, X, y)\n\n# Display result\n# print(f\"Log-likelihood at initial beta (zeros): {log_likelihood:.4f}\")\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\n# One-hot encode region and fix age/age_squared\nregion_dummies = pd.get_dummies(df_blueprinty[\"region\"], drop_first=True)\nage = df_blueprinty[\"age\"]\n\nX = pd.concat([\n    pd.Series(1, index=age.index, name=\"intercept\"),\n    age.rename(\"age\"),\n    (age ** 2 / 100).rename(\"age_squared\"),  # scaled\n    region_dummies,\n    df_blueprinty[\"iscustomer\"]\n], axis=1).astype(float)\n\ny = df_blueprinty[\"patents\"].values\nX_matrix = X.to_numpy()\n\n# Poisson negative log-likelihood\ndef neg_loglikelihood_beta(beta, X, y):\n    lambda_ = np.exp(X @ beta)\n    return -np.sum(y * np.log(lambda_) - lambda_ - gammaln(y + 1))\n\n# Run optimizer\nbeta_init = np.zeros(X_matrix.shape[1])\nresult = minimize(neg_loglikelihood_beta, beta_init, args=(X_matrix, y), method=\"BFGS\")\nbeta_hat = result.x\n\n# Hessian and standard errors\ndef hessian_poisson(beta, X):\n    lambda_ = np.exp(X @ beta)\n    W = np.diag(lambda_)\n    return X.T @ W @ X\n\nH = hessian_poisson(beta_hat, X_matrix)\ncov_matrix = np.linalg.inv(H)  # should work now\nstandard_errors = np.sqrt(np.diag(cov_matrix))\n\n# Output table\ncoef_table = pd.DataFrame({\n    \"Coefficient\": beta_hat,\n    \"Std. Error\": standard_errors\n}, index=X.columns).round(4)\n\ncoef_table\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.5089\n0.1832\n\n\nage\n0.1486\n0.0139\n\n\nage_squared\n-0.2970\n0.0258\n\n\nNortheast\n0.0292\n0.0436\n\n\nNorthwest\n-0.0176\n0.0538\n\n\nSouth\n0.0566\n0.0527\n\n\nSouthwest\n0.0506\n0.0472\n\n\niscustomer\n0.2076\n0.0309\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport statsmodels.api as sm\nimport pandas as pd\n\n# Rebuild the design matrix with correct naming and scaling\nregion_dummies = pd.get_dummies(df_blueprinty[\"region\"], drop_first=True)\nage = df_blueprinty[\"age\"]\n\nX_glm = pd.concat([\n    pd.Series(1, index=age.index, name=\"intercept\"),\n    age.rename(\"age\"),\n    (age ** 2 / 100).rename(\"age_squared\"),\n    region_dummies,\n    df_blueprinty[\"iscustomer\"]\n], axis=1).astype(float)\n\ny_glm = df_blueprinty[\"patents\"]\n\n# Fit model using statsmodels GLM with Poisson family\nmodel = sm.GLM(y_glm, X_glm, family=sm.families.Poisson())\nresults = model.fit()\n\n# Create results table\nglm_table = pd.DataFrame({\n    \"GLM Coefficient\": results.params,\n    \"GLM Std. Error\": results.bse\n}).round(4)\n\nglm_table\n\n\n\n\n\n\n\n\n\nGLM Coefficient\nGLM Std. Error\n\n\n\n\nintercept\n-0.5089\n0.1832\n\n\nage\n0.1486\n0.0139\n\n\nage_squared\n-0.2970\n0.0258\n\n\nNortheast\n0.0292\n0.0436\n\n\nNorthwest\n-0.0176\n0.0538\n\n\nSouth\n0.0566\n0.0527\n\n\nSouthwest\n0.0506\n0.0472\n\n\niscustomer\n0.2076\n0.0309\n\n\n\n\n\n\n\ntodo: Interpret the results.\n\n\n\nThe results from the built-in Poisson regression model (statsmodels.GLM) closely match those obtained from our custom MLE implementation. This consistency confirms the correctness of our estimation procedure.\nKey takeaways:\n\niscustomer: The coefficient is 0.2076, which implies that being a Blueprinty customer is associated with a 21% increase in expected patent count, holding other variables constant. This supports the company’s claim that their customers tend to be more successful in securing patents.\nage and age_squared: The positive coefficient on age and negative coefficient on age_squared indicate a nonlinear relationship: the expected number of patents increases with age at first, but eventually levels off or declines slightly — a classic concave curve.\nregion dummies: Coefficients on regional variables are relatively small, suggesting modest variation in patent rates across regions compared to the base group (the dropped region).\nintercept: The intercept (-0.5089) reflects the baseline log expected count of patents for a firm with all other predictors at zero (not very interpretable on its own, but standard in GLMs).\n\nOverall, the model suggests that Blueprinty customers tend to have higher patent counts, and firm age plays a significant but diminishing role in patent output. The regional effects are comparatively minor.\n\n\n\nCode\nimport numpy as np\n\n# Copy design matrix and create two versions\nX_0 = X.copy()\nX_1 = X.copy()\nX_0[\"iscustomer\"] = 0\nX_1[\"iscustomer\"] = 1\n\n# Convert to NumPy arrays\nX0_matrix = X_0.to_numpy()\nX1_matrix = X_1.to_numpy()\n\n# Predicted patent counts under both scenarios\ny_pred_0 = np.exp(X0_matrix @ beta_hat)\ny_pred_1 = np.exp(X1_matrix @ beta_hat)\n\n# Compute average treatment effect\navg_effect = np.mean(y_pred_1 - y_pred_0)\navg_effect\n\n\n0.7927623954445165\n\n\n\n\n\nUsing our estimated Poisson regression model, we predicted the number of patents each firm would receive under two hypothetical scenarios:\n\nScenario 1: None of the firms are Blueprinty customers\n\nScenario 2: All of the firms are Blueprinty customers\n\nThis means that, on average, using Blueprinty’s software is associated with an increase of approximately 0.79 patents per firm over the 5-year period, holding all else constant.\nThis approach provides an intuitive interpretation of the model’s estimated iscustomer coefficient on the original patent count scale, rather than in terms of logged outcomes or incidence rate ratios."
  },
  {
    "objectID": "Homework2/hw2_questions.html#airbnb-case-study",
    "href": "Homework2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\n\nCode\nimport pandas as pd\n\n# Load the Airbnb dataset\ndf_airbnb = pd.read_csv(\"airbnb.csv\")\n\n# Show basic info and missing value summary\n# basic_info = df_airbnb.info()\n# missing_summary = df_airbnb.isnull().sum().sort_values(ascending=False)\n\n# df_airbnb.head(), missing_summary.head(10)\n\n\n\n\nInitial Findings\nThe Airbnb dataset consists of listings scraped from New York City in March 2017. It includes over 40,000 entries, each representing a unique listing, along with key details such as price, number of bedrooms and bathrooms, room type, and several review-based scores.\nUpon inspection, we found that several variables contain missing values, particularly the review-based scores:\n\nreview_scores_value: 10,256 missing entries\n\nreview_scores_location: 10,254 missing entries\n\nreview_scores_cleanliness: 10,195 missing entries\n\nbathrooms: 160 missing\n\nbedrooms: 76 missing\n\nThese missing values are substantial for the review scores (about 25% of the data), so we decided to drop rows with missing values on the variables relevant to our model.\nWe also note that: - Prices and number of reviews vary widely across listings\n- Most listings fall into one of three categories: “Entire home/apt”, “Private room”, or “Shared room”\n- A subset of listings are marked as “instant bookable”, which may correlate with higher customer convenience and possibly higher bookings\nIn the next step, we will build a Poisson regression model using number_of_reviews as a proxy for booking success, and explore how various listing features influence it.\n\n\nExploratory Data Analysis\n\n\nHistogram\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Select cleaned subset for EDA\ncols_to_keep = [\n    \"number_of_reviews\", \"bedrooms\", \"bathrooms\", \"price\",\n    \"review_scores_cleanliness\", \"review_scores_location\",\n    \"review_scores_value\", \"room_type\", \"instant_bookable\"\n]\n\ndf_airbnb_clean = df_airbnb[cols_to_keep].dropna().copy()\n#| label: plot-number-of-reviews\n#| fig-cap: \"Distribution of Number of Reviews\"\n#| fig-width: 8\n#| fig-height: 6\n#| label: plot-number-of-reviews\n#| fig-cap: \"Distribution of Number of Reviews\"\n#| fig-width: 8\n#| fig-height: 6\n\nnice_blue = \"#1f77b4\"  # a clean, professional shade of blue\n\nplt.figure(figsize=(8, 6))\nsns.histplot(df_airbnb_clean[\"number_of_reviews\"], bins=25, color=nice_blue)\nplt.xlabel(\"Number of Reviews\")\nplt.ylabel(\"Count\")\nplt.title(\"Distribution of Number of Reviews\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nMost listings have fewer than 50 reviews, with a long right tail. This suggests the data are heavily skewed and supports the use of a Poisson model for count outcomes.\n\n\nDistribution of Reviews by Room Type - Boxplot\nThe plot above compares the distribution of review counts across different Airbnb room types.\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.boxplot(\n    data=df_airbnb_clean,\n    x=\"room_type\",\n    y=\"number_of_reviews\",\n    hue=\"room_type\",\n    palette=[\"#66B2D9\", \"#E9965B\", \"#66D3A6\"],\n    showfliers=False,\n    legend=False\n)\nplt.xticks(rotation=10, fontsize=10)\nplt.yticks(fontsize=10)\nplt.xlabel(\"Room Type\", fontsize=12)\nplt.ylabel(\"Number of Reviews\", fontsize=12)\nplt.title(\"Distribution of Reviews by Room Type\", fontsize=14)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDistribution of Price per Night\n\n\n\n\n\nPrivate rooms and entire homes/apartments have similar median review counts, with private rooms showing slightly more variation.\nShared rooms tend to have slightly fewer reviews overall, with a lower maximum and tighter spread.\nAll room types exhibit a right-skewed distribution, with some listings receiving significantly more reviews than typical.\n\nThese findings suggest that room type may play a modest role in driving the number of reviews (i.e., bookings), making it a useful categorical predictor for the Poisson regression model.\n\n\nCorrelation Matrix\nThe correlation matrix above shows pairwise Pearson correlations between all numeric variables in the Airbnb dataset.\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Compute correlation matrix (numeric variables only)\ncorr_matrix = df_airbnb_clean.select_dtypes(include=\"number\").corr()\n\n# Plot the heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", linewidths=0.5)\nplt.xticks(rotation=45, ha=\"right\", fontsize=10)\nplt.title(\"Correlation Matrix of Numeric Variables\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nReview scores (cleanliness, location, value) are moderately correlated with one another — especially cleanliness and value (ρ ≈ 0.62).\nPrice has weak correlations with most other variables, but a modest positive correlation with number of bedrooms (ρ ≈ 0.29).\nNumber of reviews, our proxy for bookings, shows very weak correlations with the other numeric variables — indicating that categorical variables (like room type or instant bookability) may explain more variation in review counts.\n\nThis analysis supports including review scores, room features, and booking features in a Poisson model to explain variation in review counts.\n\n\nPoisson Regression Model\n\n\nCode\nimport pandas as pd\nimport numpy as np\n\n# Recreate clean dataset\ncols_to_use = [\n    \"number_of_reviews\", \"bedrooms\", \"bathrooms\", \"price\",\n    \"review_scores_cleanliness\", \"review_scores_location\", \"review_scores_value\",\n    \"room_type\", \"instant_bookable\"\n]\ndf_airbnb_model = df_airbnb[cols_to_use].dropna().copy()\n\n# Log-transform price to handle skew (add 1 to avoid log(0))\ndf_airbnb_model[\"log_price\"] = np.log1p(df_airbnb_model[\"price\"])\n\n# One-hot encode room_type (drop one category)\nroom_dummies = pd.get_dummies(df_airbnb_model[\"room_type\"], drop_first=True)\n\n# Encode instant_bookable as binary\ndf_airbnb_model[\"instant_bookable\"] = df_airbnb_model[\"instant_bookable\"].map({\"f\": 0, \"t\": 1})\n\n# Build design matrix X\nX = pd.concat([\n    pd.Series(1, index=df_airbnb_model.index, name=\"intercept\"),\n    df_airbnb_model[[\n        \"log_price\", \"bedrooms\", \"bathrooms\",\n        \"review_scores_cleanliness\", \"review_scores_location\", \"review_scores_value\",\n        \"instant_bookable\"\n    ]],\n    room_dummies\n], axis=1).astype(float)\n\ny = df_airbnb_model[\"number_of_reviews\"].values\nX_matrix = X.to_numpy()\n\n\n\n\nCode\nimport statsmodels.api as sm\nimport pandas as pd\n\n# Fit the Poisson regression model using GLM\nmodel = sm.GLM(y, X, family=sm.families.Poisson())\nresults = model.fit()\n\n# Display coefficients and standard errors\npoisson_table = pd.DataFrame({\n    \"Coefficient\": results.params,\n    \"Std. Error\": results.bse\n}).round(4)\n\npoisson_table\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n3.0725\n0.0192\n\n\nlog_price\n0.1348\n0.0029\n\n\nbedrooms\n0.0468\n0.0020\n\n\nbathrooms\n-0.1520\n0.0037\n\n\nreview_scores_cleanliness\n0.1088\n0.0015\n\n\nreview_scores_location\n-0.0975\n0.0016\n\n\nreview_scores_value\n-0.0797\n0.0018\n\n\ninstant_bookable\n0.3408\n0.0029\n\n\nPrivate room\n0.0850\n0.0034\n\n\nShared room\n-0.1067\n0.0091\n\n\n\n\n\n\n\n\n\nInterpretation of Poisson Regression Coefficients\nThe coefficient table shows the log-linear impact of each variable on the expected number of reviews:\n\nlog_price (0.1348): A 1-unit increase in the log price (i.e., roughly a 100% increase in price) is associated with a 0.1348 increase in the log count of reviews. This suggests that more expensive listings tend to get slightly more reviews, though the effect is modest.\nbedrooms (0.0468): Each additional bedroom is associated with a ~4.7% increase in expected review count (see IRR interpretation below).\nbathrooms (-0.1520): Surprisingly, each additional bathroom is associated with a lower expected review count — possibly due to larger units being less frequently booked.\nreview_scores_cleanliness (0.1088): A 1-point increase in cleanliness score leads to higher expected review counts — a sign that perceived cleanliness drives engagement.\nreview_scores_location and value both have negative coefficients, suggesting lower booking volume with higher perceived scores, possibly due to pricing or neighborhood quirks.\ninstant_bookable (0.3408): Listings that are instantly bookable receive significantly more reviews, indicating that booking convenience strongly influences customer engagement.\nRoom Types:\n\nPrivate room (0.085): More reviews than the baseline (entire home/apt)\nShared room (-0.1067): Fewer reviews than baseline\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\n\n# Compute IRRs and 95% confidence intervals\nirr = np.exp(results.params)\nirr_lower = np.exp(results.params - 1.96 * results.bse)\nirr_upper = np.exp(results.params + 1.96 * results.bse)\n\n# Combine into a table\nirr_table = pd.DataFrame({\n    \"IRR\": irr,\n    \"95% CI Lower\": irr_lower,\n    \"95% CI Upper\": irr_upper\n}).round(3)\n\nirr_table\n\n\n\n\n\n\n\n\n\nIRR\n95% CI Lower\n95% CI Upper\n\n\n\n\nintercept\n21.595\n20.796\n22.425\n\n\nlog_price\n1.144\n1.138\n1.151\n\n\nbedrooms\n1.048\n1.044\n1.052\n\n\nbathrooms\n0.859\n0.853\n0.865\n\n\nreview_scores_cleanliness\n1.115\n1.112\n1.118\n\n\nreview_scores_location\n0.907\n0.904\n0.910\n\n\nreview_scores_value\n0.923\n0.920\n0.927\n\n\ninstant_bookable\n1.406\n1.398\n1.414\n\n\nPrivate room\n1.089\n1.082\n1.096\n\n\nShared room\n0.899\n0.883\n0.915\n\n\n\n\n\n\n\n\n\nIncidence Rate Ratio (IRR) Interpretation\nExponentiating the coefficients gives us IRRs — more intuitive multiplicative effects on review count:\n\ninstant_bookable (IRR = 1.406): Listings with instant booking receive ~40.6% more reviews, on average, than those without it.\nlog_price (1.144): A 1-unit increase in log price is associated with a 14.4% increase in expected reviews.\nbedrooms (1.048): Each additional bedroom increases expected review count by ~4.8%.\nbathrooms (0.859): Each additional bathroom reduces expected review count by about 14.1%.\nreview_scores_cleanliness (1.115): Each 1-point increase in cleanliness score is associated with ~11.5% more reviews.\nShared room (0.899): Shared rooms receive ~10% fewer reviews than the reference category (entire home/apt).\n\nOverall, the IRRs provide strong evidence that instant booking, cleanliness, and room configuration are significant predictors of review volume — your proxy for demand."
  }
]