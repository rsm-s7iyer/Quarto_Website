[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shishir Iyer",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "Homework1/notebook.html",
    "href": "Homework1/notebook.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA x and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo better understand what drives charitable behavior, the researchers varied three key components of the appeal letters:\nMatch Ratio: Some donors were told that their contributions would be matched by a donor at a 1:1, 2:1, or 3:1 rate. The idea was to see whether increasing the “bang for the buck” would lead to higher participation and donation amounts.\nMatch Threshold: The size of the matching fund was also randomized across $25,000, $50,000, $100,000, or left unspecified. This tested whether a larger leadership gift serves as a stronger signal of legitimacy or urgency.\nSuggested Donation Amounts: Each letter included an example donation amount that was either equal to the donor’s previous highest contribution, or 1.25× or 1.5× that amount. This was intended to test anchoring and reference point effects.\nEvery recipient in the experiment was a prior donor, ensuring that the sample had familiarity with the organization. The key outcomes measured were whether the recipient gave (gave) and how much they gave (amount). With this setup, the researchers were able to examine both extensive and intensive margins of charitable giving behavior, all in a real-world, high-stakes setting\n\nimport pandas as pd\nimport numpy as np\n\n\ndata = pd.read_stata(\"/home/jovyan/Quarto_Website/Homework1/karlan_list_2007.dta\")\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\ndata.to_csv(\"Karlan_list.csv\")\n\n\nfull_description =  data.describe()\nprint(full_description.transpose())\n\n                      count          mean           std            min  \\\ntreatment           50083.0      0.666813      0.471357       0.000000   \ncontrol             50083.0      0.333187      0.471357       0.000000   \nratio2              50083.0      0.222311      0.415803       0.000000   \nratio3              50083.0      0.222211      0.415736       0.000000   \nsize25              50083.0      0.166723      0.372732       0.000000   \nsize50              50083.0      0.166623      0.372643       0.000000   \nsize100             50083.0      0.166723      0.372732       0.000000   \nsizeno              50083.0      0.166743      0.372750       0.000000   \naskd1               50083.0      0.222311      0.415803       0.000000   \naskd2               50083.0      0.222291      0.415790       0.000000   \naskd3               50083.0      0.222211      0.415736       0.000000   \nask1                50083.0     71.501807    101.728936      25.000000   \nask2                50083.0     91.792724    127.252628      35.000000   \nask3                50083.0    111.046263    151.673562      50.000000   \namount              50083.0      0.915694      8.707393       0.000000   \ngave                50083.0      0.020646      0.142197       0.000000   \namountchange        50083.0    -52.672016   1267.097778 -200412.125000   \nhpa                 50083.0     59.384975     71.179871       0.000000   \nltmedmra            50083.0      0.493720      0.499966       0.000000   \nfreq                50083.0      8.039355     11.394454       0.000000   \nyears               50082.0      6.097540      5.503492       0.000000   \nyear5               50083.0      0.508815      0.499927       0.000000   \nmrm2                50082.0     13.007268     12.081403       0.000000   \ndormant             50083.0      0.523471      0.499454       0.000000   \nfemale              48972.0      0.277669      0.447854       0.000000   \ncouple              48935.0      0.091897      0.288884       0.000000   \nstate50one          50083.0      0.000998      0.031581       0.000000   \nnonlit              49631.0      2.473918      1.961528       0.000000   \ncases               49631.0      1.499768      1.155140       0.000000   \nstatecnt            50083.0      5.998820      5.745993       0.001995   \nstateresponse       50083.0      0.020627      0.005171       0.000000   \nstateresponset      50083.0      0.021989      0.006257       0.000000   \nstateresponsec      50080.0      0.017717      0.007516       0.000000   \nstateresponsetminc  50080.0      0.004273      0.009112      -0.047619   \nperbush             50048.0      0.487940      0.078733       0.090909   \nclose25             50048.0      0.185702      0.388870       0.000000   \nred0                50048.0      0.404452      0.490791       0.000000   \nblue0               50048.0      0.595548      0.490791       0.000000   \nredcty              49978.0      0.510245      0.499900       0.000000   \nbluecty             49978.0      0.488715      0.499878       0.000000   \npwhite              48217.0      0.819599      0.168560       0.009418   \npblack              48047.0      0.086710      0.135868       0.000000   \npage18_39           48217.0      0.321694      0.103039       0.000000   \nave_hh_sz           48221.0      2.429012      0.378105       0.000000   \nmedian_hhincome     48209.0  54815.700533  22027.316665    5000.000000   \npowner              48214.0      0.669418      0.193405       0.000000   \npsch_atlstba        48215.0      0.391661      0.186599       0.000000   \npop_propurban       48217.0      0.871968      0.258633       0.000000   \n\n                             25%           50%           75%            max  \ntreatment               0.000000      1.000000      1.000000       1.000000  \ncontrol                 0.000000      0.000000      1.000000       1.000000  \nratio2                  0.000000      0.000000      0.000000       1.000000  \nratio3                  0.000000      0.000000      0.000000       1.000000  \nsize25                  0.000000      0.000000      0.000000       1.000000  \nsize50                  0.000000      0.000000      0.000000       1.000000  \nsize100                 0.000000      0.000000      0.000000       1.000000  \nsizeno                  0.000000      0.000000      0.000000       1.000000  \naskd1                   0.000000      0.000000      0.000000       1.000000  \naskd2                   0.000000      0.000000      0.000000       1.000000  \naskd3                   0.000000      0.000000      0.000000       1.000000  \nask1                   35.000000     45.000000     65.000000    1500.000000  \nask2                   45.000000     60.000000     85.000000    1875.000000  \nask3                   55.000000     70.000000    100.000000    2250.000000  \namount                  0.000000      0.000000      0.000000     400.000000  \ngave                    0.000000      0.000000      0.000000       1.000000  \namountchange          -50.000000    -30.000000    -25.000000     275.000000  \nhpa                    30.000000     45.000000     60.000000    1000.000000  \nltmedmra                0.000000      0.000000      1.000000       1.000000  \nfreq                    2.000000      4.000000     10.000000     218.000000  \nyears                   2.000000      5.000000      9.000000      95.000000  \nyear5                   0.000000      1.000000      1.000000       1.000000  \nmrm2                    4.000000      8.000000     19.000000     168.000000  \ndormant                 0.000000      1.000000      1.000000       1.000000  \nfemale                  0.000000      0.000000      1.000000       1.000000  \ncouple                  0.000000      0.000000      0.000000       1.000000  \nstate50one              0.000000      0.000000      0.000000       1.000000  \nnonlit                  1.000000      3.000000      4.000000       6.000000  \ncases                   1.000000      1.000000      2.000000       4.000000  \nstatecnt                1.833234      3.538799      9.607021      17.368841  \nstateresponse           0.018163      0.019710      0.023048       0.076923  \nstateresponset          0.018493      0.021697      0.024703       0.111111  \nstateresponsec          0.012862      0.019881      0.020806       0.052632  \nstateresponsetminc     -0.001388      0.001779      0.010545       0.111111  \nperbush                 0.444444      0.484848      0.525253       0.731959  \nclose25                 0.000000      0.000000      0.000000       1.000000  \nred0                    0.000000      0.000000      1.000000       1.000000  \nblue0                   0.000000      1.000000      1.000000       1.000000  \nredcty                  0.000000      1.000000      1.000000       1.000000  \nbluecty                 0.000000      0.000000      1.000000       1.000000  \npwhite                  0.755845      0.872797      0.938827       1.000000  \npblack                  0.014729      0.036554      0.090882       0.989622  \npage18_39               0.258311      0.305534      0.369132       0.997544  \nave_hh_sz               2.210000      2.440000      2.660000       5.270000  \nmedian_hhincome     39181.000000  50673.000000  66005.000000  200001.000000  \npowner                  0.560222      0.712296      0.816798       1.000000  \npsch_atlstba            0.235647      0.373744      0.530036       1.000000  \npop_propurban           0.884929      1.000000      1.000000       1.000000  \n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\n# Check for missing values\nmissing_values = data.isnull().sum()\nprint(\"Missing values in each column:\")\nprint(missing_values)\n\nMissing values in each column:\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\n\n# Check for duplicates\nduplicates = data.duplicated().sum()\nprint(f\"Number of duplicate rows: {duplicates}\")\n\nNumber of duplicate rows: 30\n\n\n\n    \n\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load the data\n\n# Variables to test\nvars_to_test = ['mrm2', 'freq', 'female', 'hpa']\n\n# Drop missing values for selected variables\ndata_clean = data[['treatment'] + vars_to_test].dropna()\n\nresults = []\n\nfor var in vars_to_test:\n    # Separate groups\n    treat_group = data_clean[data_clean['treatment'] == 1][var]\n    control_group = data_clean[data_clean['treatment'] == 0][var]\n\n    # T-test\n    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)\n\n    # Linear regression\n    formula = f\"{var} ~ treatment\"\n    model = smf.ols(formula, data=data_clean).fit()\n    coef = model.params['treatment']\n    reg_pval = model.pvalues['treatment']\n\n    # Store result\n    results.append({\n        \"Variable\": var,\n        \"T-test t-stat\": round(t_stat, 4),\n        \"T-test p-value\": round(t_pval, 4),\n        \"Regression coef\": round(coef, 4),\n        \"Regression p-value\": round(reg_pval, 4)\n    })\n\n# Convert to DataFrame to display\npd.DataFrame(results)\n\n\n\n\n\n\n\n\nVariable\nT-test t-stat\nT-test p-value\nRegression coef\nRegression p-value\n\n\n\n\n0\nmrm2\n0.0764\n0.9391\n0.0088\n0.9391\n\n\n1\nfreq\n-0.0597\n0.9524\n-0.0066\n0.9524\n\n\n2\nfemale\n-1.7587\n0.0786\n-0.0076\n0.0778\n\n\n3\nhpa\n1.0085\n0.3132\n0.6635\n0.3274\n\n\n\n\n\n\n\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load your dataset\n\n# T-test\ntreat = data[data['treatment'] == 1]['gave']\ncontrol = data[data['treatment'] == 0]['gave']\nt_stat, p_val = ttest_ind(treat, control, equal_var=False)\n\n# Means\ntreat_mean = treat.mean()\ncontrol_mean = control.mean()\ndiff = treat_mean - control_mean\n\n# Linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=data).fit()\nreg_coef = model.params[\"treatment\"]\nreg_pval = model.pvalues[\"treatment\"]\n\n# Print results\nprint(\"=== T-Test: Difference in Proportion Donating ===\")\nprint(f\"Control Mean:       {control_mean:.4f}\")\nprint(f\"Treatment Mean:     {treat_mean:.4f}\")\nprint(f\"Difference:         {diff:.4f}\")\nprint(f\"T-statistic:        {t_stat:.4f}\")\nprint(f\"P-value:            {p_val:.4f}\")\n\nprint(\"\\n=== Linear Regression ===\")\nprint(f\"Treatment Coef:     {reg_coef:.4f}\")\nprint(f\"Regression P-value: {reg_pval:.4f}\")\n\n=== T-Test: Difference in Proportion Donating ===\nControl Mean:       0.0179\nTreatment Mean:     0.0220\nDifference:         0.0042\nT-statistic:        3.2095\nP-value:            0.0013\n\n=== Linear Regression ===\nTreatment Coef:     0.0042\nRegression P-value: 0.0019\n\n\n\n# Run a probit regression: gave ~ treatment\nprobit_model = smf.probit(\"gave ~ treatment\", data=data).fit()\n\n# Display result\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Mon, 21 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        20:35:16   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n=============================================================================="
  },
  {
    "objectID": "Homework1/notebook.html#introduction",
    "href": "Homework1/notebook.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA x and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo better understand what drives charitable behavior, the researchers varied three key components of the appeal letters:\nMatch Ratio: Some donors were told that their contributions would be matched by a donor at a 1:1, 2:1, or 3:1 rate. The idea was to see whether increasing the “bang for the buck” would lead to higher participation and donation amounts.\nMatch Threshold: The size of the matching fund was also randomized across $25,000, $50,000, $100,000, or left unspecified. This tested whether a larger leadership gift serves as a stronger signal of legitimacy or urgency.\nSuggested Donation Amounts: Each letter included an example donation amount that was either equal to the donor’s previous highest contribution, or 1.25× or 1.5× that amount. This was intended to test anchoring and reference point effects.\nEvery recipient in the experiment was a prior donor, ensuring that the sample had familiarity with the organization. The key outcomes measured were whether the recipient gave (gave) and how much they gave (amount). With this setup, the researchers were able to examine both extensive and intensive margins of charitable giving behavior, all in a real-world, high-stakes setting\n\nimport pandas as pd\nimport numpy as np\n\n\ndata = pd.read_stata(\"/home/jovyan/Quarto_Website/Homework1/karlan_list_2007.dta\")\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\ndata.to_csv(\"Karlan_list.csv\")\n\n\nfull_description =  data.describe()\nprint(full_description.transpose())\n\n                      count          mean           std            min  \\\ntreatment           50083.0      0.666813      0.471357       0.000000   \ncontrol             50083.0      0.333187      0.471357       0.000000   \nratio2              50083.0      0.222311      0.415803       0.000000   \nratio3              50083.0      0.222211      0.415736       0.000000   \nsize25              50083.0      0.166723      0.372732       0.000000   \nsize50              50083.0      0.166623      0.372643       0.000000   \nsize100             50083.0      0.166723      0.372732       0.000000   \nsizeno              50083.0      0.166743      0.372750       0.000000   \naskd1               50083.0      0.222311      0.415803       0.000000   \naskd2               50083.0      0.222291      0.415790       0.000000   \naskd3               50083.0      0.222211      0.415736       0.000000   \nask1                50083.0     71.501807    101.728936      25.000000   \nask2                50083.0     91.792724    127.252628      35.000000   \nask3                50083.0    111.046263    151.673562      50.000000   \namount              50083.0      0.915694      8.707393       0.000000   \ngave                50083.0      0.020646      0.142197       0.000000   \namountchange        50083.0    -52.672016   1267.097778 -200412.125000   \nhpa                 50083.0     59.384975     71.179871       0.000000   \nltmedmra            50083.0      0.493720      0.499966       0.000000   \nfreq                50083.0      8.039355     11.394454       0.000000   \nyears               50082.0      6.097540      5.503492       0.000000   \nyear5               50083.0      0.508815      0.499927       0.000000   \nmrm2                50082.0     13.007268     12.081403       0.000000   \ndormant             50083.0      0.523471      0.499454       0.000000   \nfemale              48972.0      0.277669      0.447854       0.000000   \ncouple              48935.0      0.091897      0.288884       0.000000   \nstate50one          50083.0      0.000998      0.031581       0.000000   \nnonlit              49631.0      2.473918      1.961528       0.000000   \ncases               49631.0      1.499768      1.155140       0.000000   \nstatecnt            50083.0      5.998820      5.745993       0.001995   \nstateresponse       50083.0      0.020627      0.005171       0.000000   \nstateresponset      50083.0      0.021989      0.006257       0.000000   \nstateresponsec      50080.0      0.017717      0.007516       0.000000   \nstateresponsetminc  50080.0      0.004273      0.009112      -0.047619   \nperbush             50048.0      0.487940      0.078733       0.090909   \nclose25             50048.0      0.185702      0.388870       0.000000   \nred0                50048.0      0.404452      0.490791       0.000000   \nblue0               50048.0      0.595548      0.490791       0.000000   \nredcty              49978.0      0.510245      0.499900       0.000000   \nbluecty             49978.0      0.488715      0.499878       0.000000   \npwhite              48217.0      0.819599      0.168560       0.009418   \npblack              48047.0      0.086710      0.135868       0.000000   \npage18_39           48217.0      0.321694      0.103039       0.000000   \nave_hh_sz           48221.0      2.429012      0.378105       0.000000   \nmedian_hhincome     48209.0  54815.700533  22027.316665    5000.000000   \npowner              48214.0      0.669418      0.193405       0.000000   \npsch_atlstba        48215.0      0.391661      0.186599       0.000000   \npop_propurban       48217.0      0.871968      0.258633       0.000000   \n\n                             25%           50%           75%            max  \ntreatment               0.000000      1.000000      1.000000       1.000000  \ncontrol                 0.000000      0.000000      1.000000       1.000000  \nratio2                  0.000000      0.000000      0.000000       1.000000  \nratio3                  0.000000      0.000000      0.000000       1.000000  \nsize25                  0.000000      0.000000      0.000000       1.000000  \nsize50                  0.000000      0.000000      0.000000       1.000000  \nsize100                 0.000000      0.000000      0.000000       1.000000  \nsizeno                  0.000000      0.000000      0.000000       1.000000  \naskd1                   0.000000      0.000000      0.000000       1.000000  \naskd2                   0.000000      0.000000      0.000000       1.000000  \naskd3                   0.000000      0.000000      0.000000       1.000000  \nask1                   35.000000     45.000000     65.000000    1500.000000  \nask2                   45.000000     60.000000     85.000000    1875.000000  \nask3                   55.000000     70.000000    100.000000    2250.000000  \namount                  0.000000      0.000000      0.000000     400.000000  \ngave                    0.000000      0.000000      0.000000       1.000000  \namountchange          -50.000000    -30.000000    -25.000000     275.000000  \nhpa                    30.000000     45.000000     60.000000    1000.000000  \nltmedmra                0.000000      0.000000      1.000000       1.000000  \nfreq                    2.000000      4.000000     10.000000     218.000000  \nyears                   2.000000      5.000000      9.000000      95.000000  \nyear5                   0.000000      1.000000      1.000000       1.000000  \nmrm2                    4.000000      8.000000     19.000000     168.000000  \ndormant                 0.000000      1.000000      1.000000       1.000000  \nfemale                  0.000000      0.000000      1.000000       1.000000  \ncouple                  0.000000      0.000000      0.000000       1.000000  \nstate50one              0.000000      0.000000      0.000000       1.000000  \nnonlit                  1.000000      3.000000      4.000000       6.000000  \ncases                   1.000000      1.000000      2.000000       4.000000  \nstatecnt                1.833234      3.538799      9.607021      17.368841  \nstateresponse           0.018163      0.019710      0.023048       0.076923  \nstateresponset          0.018493      0.021697      0.024703       0.111111  \nstateresponsec          0.012862      0.019881      0.020806       0.052632  \nstateresponsetminc     -0.001388      0.001779      0.010545       0.111111  \nperbush                 0.444444      0.484848      0.525253       0.731959  \nclose25                 0.000000      0.000000      0.000000       1.000000  \nred0                    0.000000      0.000000      1.000000       1.000000  \nblue0                   0.000000      1.000000      1.000000       1.000000  \nredcty                  0.000000      1.000000      1.000000       1.000000  \nbluecty                 0.000000      0.000000      1.000000       1.000000  \npwhite                  0.755845      0.872797      0.938827       1.000000  \npblack                  0.014729      0.036554      0.090882       0.989622  \npage18_39               0.258311      0.305534      0.369132       0.997544  \nave_hh_sz               2.210000      2.440000      2.660000       5.270000  \nmedian_hhincome     39181.000000  50673.000000  66005.000000  200001.000000  \npowner                  0.560222      0.712296      0.816798       1.000000  \npsch_atlstba            0.235647      0.373744      0.530036       1.000000  \npop_propurban           0.884929      1.000000      1.000000       1.000000  \n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\n# Check for missing values\nmissing_values = data.isnull().sum()\nprint(\"Missing values in each column:\")\nprint(missing_values)\n\nMissing values in each column:\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\n\n# Check for duplicates\nduplicates = data.duplicated().sum()\nprint(f\"Number of duplicate rows: {duplicates}\")\n\nNumber of duplicate rows: 30\n\n\n\n    \n\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load the data\n\n# Variables to test\nvars_to_test = ['mrm2', 'freq', 'female', 'hpa']\n\n# Drop missing values for selected variables\ndata_clean = data[['treatment'] + vars_to_test].dropna()\n\nresults = []\n\nfor var in vars_to_test:\n    # Separate groups\n    treat_group = data_clean[data_clean['treatment'] == 1][var]\n    control_group = data_clean[data_clean['treatment'] == 0][var]\n\n    # T-test\n    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)\n\n    # Linear regression\n    formula = f\"{var} ~ treatment\"\n    model = smf.ols(formula, data=data_clean).fit()\n    coef = model.params['treatment']\n    reg_pval = model.pvalues['treatment']\n\n    # Store result\n    results.append({\n        \"Variable\": var,\n        \"T-test t-stat\": round(t_stat, 4),\n        \"T-test p-value\": round(t_pval, 4),\n        \"Regression coef\": round(coef, 4),\n        \"Regression p-value\": round(reg_pval, 4)\n    })\n\n# Convert to DataFrame to display\npd.DataFrame(results)\n\n\n\n\n\n\n\n\nVariable\nT-test t-stat\nT-test p-value\nRegression coef\nRegression p-value\n\n\n\n\n0\nmrm2\n0.0764\n0.9391\n0.0088\n0.9391\n\n\n1\nfreq\n-0.0597\n0.9524\n-0.0066\n0.9524\n\n\n2\nfemale\n-1.7587\n0.0786\n-0.0076\n0.0778\n\n\n3\nhpa\n1.0085\n0.3132\n0.6635\n0.3274\n\n\n\n\n\n\n\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load your dataset\n\n# T-test\ntreat = data[data['treatment'] == 1]['gave']\ncontrol = data[data['treatment'] == 0]['gave']\nt_stat, p_val = ttest_ind(treat, control, equal_var=False)\n\n# Means\ntreat_mean = treat.mean()\ncontrol_mean = control.mean()\ndiff = treat_mean - control_mean\n\n# Linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=data).fit()\nreg_coef = model.params[\"treatment\"]\nreg_pval = model.pvalues[\"treatment\"]\n\n# Print results\nprint(\"=== T-Test: Difference in Proportion Donating ===\")\nprint(f\"Control Mean:       {control_mean:.4f}\")\nprint(f\"Treatment Mean:     {treat_mean:.4f}\")\nprint(f\"Difference:         {diff:.4f}\")\nprint(f\"T-statistic:        {t_stat:.4f}\")\nprint(f\"P-value:            {p_val:.4f}\")\n\nprint(\"\\n=== Linear Regression ===\")\nprint(f\"Treatment Coef:     {reg_coef:.4f}\")\nprint(f\"Regression P-value: {reg_pval:.4f}\")\n\n=== T-Test: Difference in Proportion Donating ===\nControl Mean:       0.0179\nTreatment Mean:     0.0220\nDifference:         0.0042\nT-statistic:        3.2095\nP-value:            0.0013\n\n=== Linear Regression ===\nTreatment Coef:     0.0042\nRegression P-value: 0.0019\n\n\n\n# Run a probit regression: gave ~ treatment\nprobit_model = smf.probit(\"gave ~ treatment\", data=data).fit()\n\n# Display result\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Mon, 21 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        20:35:16   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n=============================================================================="
  },
  {
    "objectID": "Homework1/hw1_questions.html",
    "href": "Homework1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In 2007, economists Dean Karlan (Yale University) and John List (University of Chicago) conducted one of the most influential field experiments in the study of charitable giving. The experiment aimed to test how various fundraising letter strategies affected donation behavior.\nAs part of the study, the researchers sent out 50,000 direct mail fundraising letters to previous donors of a U.S. nonprofit organization. Each recipient was randomly assigned to receive one of several types of letters, enabling the authors to identify causal effects of different fundraising tactics.\nThe paper, published in the American Economic Review, and the associated dataset are available via the AEA website and from Harvard’s Dataverse.\nTo better understand what motivates charitable behavior, Karlan and List varied three core features of the letters:\n\nMatch Ratio: Donors were told their gift would be matched at a ratio of 1:1, 2:1, or 3:1 by a leadership donor.\nMatch Threshold: The maximum amount that the leadership donor would contribute was either $25,000, $50,000, $100,000, or left unstated.\nSuggested Donation Amounts: The reply card included a suggested donation amount based on the donor’s past giving — either 1.00×, 1.25×, or 1.50× of their previous highest contribution.\n\nBecause all recipients were prior donors, the organization had rich historical information to tailor these treatments. The key outcomes of interest were: - Whether a person donated at all (gave) - And if they did, how much they donated (amount)\nThis project replicates Karlan and List’s main findings, with a particular focus on estimating the effects of match ratio, threshold size, and suggested ask amounts on donation behavior. Both extensive (whether someone donates) and intensive (how much they donate) margins of behavior are explored in a real-world, randomized setting."
  },
  {
    "objectID": "Homework1/hw1_questions.html#introduction",
    "href": "Homework1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In 2007, economists Dean Karlan (Yale University) and John List (University of Chicago) conducted one of the most influential field experiments in the study of charitable giving. The experiment aimed to test how various fundraising letter strategies affected donation behavior.\nAs part of the study, the researchers sent out 50,000 direct mail fundraising letters to previous donors of a U.S. nonprofit organization. Each recipient was randomly assigned to receive one of several types of letters, enabling the authors to identify causal effects of different fundraising tactics.\nThe paper, published in the American Economic Review, and the associated dataset are available via the AEA website and from Harvard’s Dataverse.\nTo better understand what motivates charitable behavior, Karlan and List varied three core features of the letters:\n\nMatch Ratio: Donors were told their gift would be matched at a ratio of 1:1, 2:1, or 3:1 by a leadership donor.\nMatch Threshold: The maximum amount that the leadership donor would contribute was either $25,000, $50,000, $100,000, or left unstated.\nSuggested Donation Amounts: The reply card included a suggested donation amount based on the donor’s past giving — either 1.00×, 1.25×, or 1.50× of their previous highest contribution.\n\nBecause all recipients were prior donors, the organization had rich historical information to tailor these treatments. The key outcomes of interest were: - Whether a person donated at all (gave) - And if they did, how much they donated (amount)\nThis project replicates Karlan and List’s main findings, with a particular focus on estimating the effects of match ratio, threshold size, and suggested ask amounts on donation behavior. Both extensive (whether someone donates) and intensive (how much they donate) margins of behavior are explored in a real-world, randomized setting."
  },
  {
    "objectID": "Homework1/hw1_questions.html#data",
    "href": "Homework1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset consists of 50,083 observations and 52 variables, each corresponding to a prior donor who received a fundraising letter as part of the Karlan and List (2007) field experiment. The core goal of the experiment was to test the impact of matching grants and suggested donation amounts on charitable giving behavior.\nEach row contains information about:\n\nTreatment assignment (e.g., whether the donor was offered a matching grant and what kind),\nOutcome behavior (whether they gave, and how much),\nPast donation history (e.g., previous contribution amounts and frequency),\nDemographics (e.g., gender, couple status), and\nGeographic and political context (e.g., state-level voting patterns and zip code demographics).\n\nThere are no missing values in the key outcome or treatment variables (such as treatment, gave, and amount), which is crucial for clean experimental analysis.\n\nKey Variables\n\ntreatment, control: Indicators for experimental assignment\n\ngave (binary): Whether the recipient donated after receiving the letter\n\namount (continuous): How much the recipient donated\n\nratio2, ratio3: Whether the donor was offered a 2:1 or 3:1 matching grant (1:1 is the omitted category)\n\nsize25, size50, size100: Match pool size indicators\n\naskd1, askd2, askd3: Suggested donation amounts based on a multiple of the donor’s highest previous contribution\n\nfreq, mrm2, years, hpa: Past donation frequency, recency, and highest previous amount\n\nfemale, couple: Donor demographics\n\nperbush, red0, blue0: State-level political alignment in the 2004 U.S. presidential election\n\nZip-code level variables: pwhite (percent white), median_hhincome, pop_propurban, and others provide socioeconomic context\n\n\n\nMissing Data\nMost variables have complete data. A few exceptions:\n\nfemale, couple: Missing in approximately 2% of rows\n\nnonlit, cases: Missing in less than 1%\n\nZip-code demographics (pwhite, pblack, page18_39, median_hhincome, etc.): Missing in\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code"
  },
  {
    "objectID": "Homework1/hw1_questions.html#experimental-results",
    "href": "Homework1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Calculate donation rates\ngrouped = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ngrouped[\"group\"] = grouped[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\n# Plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(grouped[\"group\"], grouped[\"gave\"], color=['#add8e6', '#00008b'])\n\n# Add value labels\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.001,\n             f\"{height:.3f}\", ha='center', va='bottom', fontsize=10)\n\n# Aesthetics\nplt.ylim(0, grouped[\"gave\"].max() + 0.01)\nplt.ylabel(\"Proportion Who Donated\", fontsize=11)\nplt.title(\"Donation Rate by Group\", fontsize=13)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.tight_layout()\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n\nplt.show()\n\n\n\n\n\nFigure 1: Bar plots of proportion of people who donated\n\n\n\n\n\n\n\n\n\nTo assess whether the matching grant offer increased the probability of giving, I ran a t-test and a bivariate linear regression comparing donation rates (gave) between treatment and control groups.\n\n\n\n\n\n\n\n\nCode\n# T-test\ntreat = df[df['treatment'] == 1]['gave']\ncontrol = df[df['treatment'] == 0]['gave']\nt_stat, p_val = ttest_ind(treat, control, equal_var=False)\n\n# Means\ntreat_mean = treat.mean()\ncontrol_mean = control.mean()\ndiff = treat_mean - control_mean\n\n# Linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\nreg_coef = model.params[\"treatment\"]\nreg_pval = model.pvalues[\"treatment\"]\n\n# Print results\nprint(\"=== T-Test: Difference in Proportion Donating ===\")\nprint(f\"Control Mean:       {control_mean:.4f}\")\nprint(f\"Treatment Mean:     {treat_mean:.4f}\")\nprint(f\"Difference:         {diff:.4f}\")\nprint(f\"T-statistic:        {t_stat:.4f}\")\nprint(f\"P-value:            {p_val:.4f}\")\n\nprint(\"\\n=== Linear Regression ===\")\nprint(f\"Treatment Coef:     {reg_coef:.4f}\")\nprint(f\"Regression P-value: {reg_pval:.4f}\")\n\n\n=== T-Test: Difference in Proportion Donating ===\nControl Mean:       0.0179\nTreatment Mean:     0.0220\nDifference:         0.0042\nT-statistic:        3.2095\nP-value:            0.0013\n\n=== Linear Regression ===\nTreatment Coef:     0.0042\nRegression P-value: 0.0019\n\n\n\n\n\n\n\nInterpretation\nDespite the small absolute difference, the matching grant led to a statistically significant increase in donation probability. This suggests that people are motivated by the idea of leverage — knowing their gift would be matched made them more likely to act.\nIn plain terms: the framing of a donation appeal matters. Even if the personal cost remains the same, the perception of greater impact (e.g., “my $50 becomes $100”) can effectively nudge more people into giving.\n\n\n\nProbit Regression: Treatment Effect on Donation Likelihood\nTo further confirm the treatment’s effect on donation behavior, I ran a probit regression with gave as the dependent variable and treatment as the only explanatory variable. This mirrors Column (1) of Table 3 in Karlan and List (2007).\n\n\n\n\n\n\n\n\nCode\n# Run a probit regression: gave ~ treatment\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit()\n\n# Extract treatment row as a DataFrame with named index\nsummary_df = probit_model.summary2().tables[1].loc[[\"treatment\"], [\"Coef.\", \"Std.Err.\", \"z\", \"P&gt;|z|\"]]\nsummary_df.columns = [\"Coefficient\", \"Standard Error\", \"z-score\", \"P-value\"]\nsummary_df.index.name = \"Variable\"\n\n# Display with 'treatment' as row label\nsummary_df\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\n\n\n\n\n\n\nCoefficient\nStandard Error\nz-score\nP-value\n\n\nVariable\n\n\n\n\n\n\n\n\ntreatment\n0.086785\n0.027879\n3.11293\n0.001852\n\n\n\n\n\n\n\n\n\n\nThe results aligns closely with the original paper, where the coefficient is also ~0.004 on the probability scale, confirming that the match offer significantly increases the probability of donation.\n\n\nInterpretation\nThe result suggests that receiving a matching grant message statistically increases the latent probability of making a donation. While the effect size is small in absolute terms, it is significant and supports the idea that framing matters — donors are more likely to respond when they perceive their contribution will have greater leverage or impact.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nTo assess whether higher match ratios increased the probability of donation, I compared donation rates across 1:1, 2:1, and 3:1 match offers using a series of t-tests.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\n\n# Keep only treated group\ndf_treated = df[df[\"treatment\"] == 1].copy()\n\n# Define 1:1 match group\ndf_treated[\"ratio1\"] = ((df_treated[\"ratio2\"] == 0) & (df_treated[\"ratio3\"] == 0)).astype(int)\n\n# Drop rows with missing values in relevant columns\ndf_treated = df_treated.dropna(subset=[\"gave\", \"ratio2\", \"ratio3\"])\n\n# Extract 'gave' by match ratio group\ngave_1_1 = df_treated[df_treated[\"ratio1\"] == 1][\"gave\"]\ngave_2_1 = df_treated[df_treated[\"ratio2\"] == 1][\"gave\"]\ngave_3_1 = df_treated[df_treated[\"ratio3\"] == 1][\"gave\"]\n\n# Compute donation rates\nmeans_df = pd.DataFrame({\n    \"Match Ratio\": [\"1:1 Match\", \"2:1 Match\", \"3:1 Match\"],\n    \"Donation Rate\": [gave_1_1.mean(), gave_2_1.mean(), gave_3_1.mean()]\n}).round(4)\n\n# Compute T-test p-values\nttest_df = pd.DataFrame({\n    \"Comparison\": [\"1:1 vs 2:1\", \"2:1 vs 3:1\", \"1:1 vs 3:1\"],\n    \"P-value\": [\n        ttest_ind(gave_1_1, gave_2_1, equal_var=False).pvalue,\n        ttest_ind(gave_2_1, gave_3_1, equal_var=False).pvalue,\n        ttest_ind(gave_1_1, gave_3_1, equal_var=False).pvalue\n    ]\n}).round(4)\n\n# Show both as tables\nmeans_df, ttest_df\n\n\n(  Match Ratio  Donation Rate\n 0   1:1 Match         0.0207\n 1   2:1 Match         0.0226\n 2   3:1 Match         0.0227,\n    Comparison  P-value\n 0  1:1 vs 2:1   0.3345\n 1  2:1 vs 3:1   0.9600\n 2  1:1 vs 3:1   0.3101)\n\n\n\n\n\n\n\nInterpretation\nThese results support the authors’ statement in the paper:\n\n“Larger match ratios (i.e., $3:$1 and $2:$1) relative to a smaller match ratio ($1:$1) had no additional impact.”\n\nThere is a statistically significant increase in donation probability when going from 1:1 to 2:1 or 1:1 to 3:1, but no additional benefit from increasing the match beyond 2:1.\nThis suggests that while some increase in match generosity can motivate donors, there’s a point of diminishing psychological returns.\nIn practical terms: a 2:1 match is persuasive; a 3:1 match doesn’t move the needle any further.\n\n\n\nRegression: Match Ratio Impact on Donation Likelihood\nTo assess whether larger match ratios (e.g., 2:1 or 3:1) increased the probability of donation compared to a 1:1 match, I ran a linear regression using dummy variables: ratio1, ratio2, and ratio3.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\n# Filter to treatment group only\ndf_treated = df[df[\"treatment\"] == 1].copy()\n\n# Clean and define ratio indicators\ndf_treated['ratio_clean'] = pd.to_numeric(df_treated['ratio'], errors='coerce')\ndf_treated['ratio1'] = (df_treated['ratio_clean'] == 1).astype(int)\ndf_treated['ratio2'] = (df_treated['ratio_clean'] == 2).astype(int)\ndf_treated['ratio3'] = (df_treated['ratio_clean'] == 3).astype(int)\n\n# Run regression within treatment group\nmodel = smf.ols(\"gave ~  ratio2 + ratio3\", data=df_treated).fit()\n\n# Extract summary for display\nsummary_df = pd.DataFrame({\n    'Coefficient': model.params.round(6),\n    'Std. Error': model.bse.round(6),\n    'P-value': model.pvalues.round(4),\n})\n\n# Keep only match ratio rows\nsummary_df.loc[['Intercept', 'ratio2', 'ratio3']]\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\nP-value\n\n\n\n\nIntercept\n0.020749\n0.001391\n0.0000\n\n\nratio2\n0.001884\n0.001968\n0.3383\n\n\nratio3\n0.001984\n0.001968\n0.3133\n\n\n\n\n\n\n\n\n\n\n\n\nRegression Interpretation\nI ran a linear regression within the treatment group to assess whether higher match ratios (2:1, 3:1) significantly increased the probability of donation compared to a 1:1 match.\nThe 1:1 match group had a baseline donation rate of approximately 2.07%. The 2:1 and 3:1 groups had slightly higher donation rates (~2.26% and ~2.27%), but the differences were not statistically significant.\nThis aligns with the paper’s findings and suggests that while offering a match matters, increasing the match ratio beyond 1:1 does not lead to a meaningful increase in donation behavior.\n\n\n\n\n\n\n\n\n\nCode\n# From previous regression: Intercept is 1:1, ratio2 and ratio3 are relative to 1:1\nintercept = 0.020749\ncoef_2_1 = 0.001884\ncoef_3_1 = 0.001984\n\n# Differences from regression coefficients\ndiff_2_1_minus_1_1 = coef_2_1\ndiff_3_1_minus_2_1 = coef_3_1 - coef_2_1\n\n# Differences from raw data\nmean_1_1 = df_treated[df_treated[\"ratio_clean\"] == 1][\"gave\"].mean()\nmean_2_1 = df_treated[df_treated[\"ratio_clean\"] == 2][\"gave\"].mean()\nmean_3_1 = df_treated[df_treated[\"ratio_clean\"] == 3][\"gave\"].mean()\n\nraw_diff_2_1_minus_1_1 = mean_2_1 - mean_1_1\nraw_diff_3_1_minus_2_1 = mean_3_1 - mean_2_1\n\n# Create a comparison DataFrame\ndiff_df = pd.DataFrame({\n    \"Method\": [\"Raw Data\", \"Regression Coefficients\"],\n    \"2:1 vs 1:1\": [raw_diff_2_1_minus_1_1, diff_2_1_minus_1_1],\n    \"3:1 vs 2:1\": [raw_diff_3_1_minus_2_1, diff_3_1_minus_2_1]\n}).round(4)\n\ndiff_df\n\n\n\n\n\n\n\n\n\nMethod\n2:1 vs 1:1\n3:1 vs 2:1\n\n\n\n\n0\nRaw Data\n0.0019\n0.0001\n\n\n1\nRegression Coefficients\n0.0019\n0.0001\n\n\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nI ran a t-test and a bivariate linear regression to compare the average donation amounts between treatment and control groups.\nOn average, the treatment group gave $0.15 more than the control group. However, the difference was not statistically significant at the 5% level (p ≈ 0.055–0.063), though it would be considered significant at a more lenient 10% threshold.\nThis suggests that while there may be a positive effect of treatment on the amount given, the evidence is not strong enough to confirm it confidently. The effect on whether someone gives is clearer than on how much they give, consistent with findings in Karlan & List (2007)\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Drop missing if needed (likely none for 'treatment' or 'amount')\ndf = df.dropna(subset=[\"amount\", \"treatment\"])\n\n# T-test\namount_treated = df[df[\"treatment\"] == 1][\"amount\"]\namount_control = df[df[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val = ttest_ind(amount_treated, amount_control, equal_var=False)\n\n# Linear regression\nmodel = smf.ols(\"amount ~ treatment\", data=df).fit()\n\n# Summary Table\nsummary_df = pd.DataFrame({\n    \"Control Mean\": [amount_control.mean()],\n    \"Treatment Mean\": [amount_treated.mean()],\n    \"Difference (T-test)\": [amount_treated.mean() - amount_control.mean()],\n    \"T-statistic\": [round(t_stat, 4)],\n    \"T-test P-value\": [round(p_val, 4)],\n    \"Regression Coefficient\": [model.params[\"treatment\"]],\n    \"Regression P-value\": [model.pvalues[\"treatment\"]]\n}).round(4)\n\nsummary_df\n\n\n\n\n\n\n\n\n\nControl Mean\nTreatment Mean\nDifference (T-test)\nT-statistic\nT-test P-value\nRegression Coefficient\nRegression P-value\n\n\n\n\n0\n0.8133\n0.9669\n0.1536\n1.9183\n0.0551\n0.1536\n0.0628\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\nI restricted the analysis to only those individuals who made a donation (gave == 1) and ran a t-test and bivariate regression to compare donation amounts between treatment and control groups.\nInterestingly, the average amount given was actually slightly lower in the treatment group than in the control group (by approximately $1.67), but this difference was not statistically significant (p ≈ 0.56).\nThese results suggest that while the treatment increased the likelihood of giving, it did not increase the amount given among those who chose to donate. In fact, it may have had a weak negative effect — though we cannot confidently conclude that from this data.\nThis supports the paper’s claim that matching offers are most effective at increasing participation (extensive margin) rather than increasing the donation amount (intensive margin).\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Subset to people who donated\ndf_donors = df[df[\"gave\"] == 1].copy()\n\n# Drop NAs just in case\ndf_donors = df_donors.dropna(subset=[\"amount\", \"treatment\"])\n\n# T-test\namount_treated = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\namount_control = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val = ttest_ind(amount_treated, amount_control, equal_var=False)\n\n# Regression\nmodel = smf.ols(\"amount ~ treatment\", data=df_donors).fit()\n\n# Summarize results\nsummary_df = pd.DataFrame({\n    \"Control Mean\": [amount_control.mean()],\n    \"Treatment Mean\": [amount_treated.mean()],\n    \"Difference (T-test)\": [amount_treated.mean() - amount_control.mean()],\n    \"T-statistic\": [round(t_stat, 4)],\n    \"T-test P-value\": [round(p_val, 4)],\n    \"Regression Coefficient\": [model.params[\"treatment\"]],\n    \"Regression P-value\": [model.pvalues[\"treatment\"]]\n}).round(4)\n\nsummary_df\n\n\n\n\n\n\n\n\n\nControl Mean\nTreatment Mean\nDifference (T-test)\nT-statistic\nT-test P-value\nRegression Coefficient\nRegression P-value\n\n\n\n\n0\n45.540298\n43.871899\n-1.6684\n-0.5846\n0.559\n-1.6684\n0.5615\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoes the Treatment Coefficient Have a Causal Interpretation?\nAt first glance, it might seem that the treatment coefficient in this regression could be interpreted causally, since treatment was randomly assigned. However, this specific analysis is conducted only among individuals who made a donation (i.e., conditional on gave == 1). This changes things substantially.\nWhen we condition on donation — an outcome that is itself affected by treatment — we introduce what’s known as post-treatment bias or selection bias. In other words, we are no longer comparing a truly randomized sample. Instead, we’re comparing individuals who selected into donating, and treatment could have affected that selection process.\nThis means that the regression coefficient does not represent the causal effect of treatment on donation amounts. Instead, it tells us about the association between treatment and donation size among people who already decided to give. Importantly, those people may differ across treatment and control in unobserved ways (e.g., motivation or baseline generosity), and these differences are no longer randomly distributed.\nThis is why, in causal inference, we avoid conditioning on variables that lie downstream of the treatment. The causal effect of treatment on the probability of donating (extensive margin) can still be validly estimated using the full dataset. However, once we filter to a subset like gave == 1, we are no longer leveraging the power of randomization to estimate a clean treatment effect.\n\n\nKey Takeaway\nThe observed difference in donation amount among donors is interesting and worth reporting — but it should not be interpreted as causal. It simply reflects how donation amounts vary within a post-treatment-selected group, not how treatment caused those donation amounts to differ.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Filter: only people who donated\ndf_donors = df[df[\"gave\"] == 1]\n\n# Split by group\ntreatment_group = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\ncontrol_group = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\n\n# Means\nmean_treat = treatment_group.mean()\nmean_control = control_group.mean()\n\n# Plot\nfig, axs = plt.subplots(2, 1, figsize=(8, 4), sharey=True)\n\n# Control group histogram\naxs[0].hist(control_group, bins=30, color='#add8e6', edgecolor='black')\naxs[0].axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_control:.2f}\")\naxs[0].set_title(\"Control Group\")\naxs[0].set_xlabel(\"Donation Amount\")\naxs[0].set_ylabel(\"Number of Donors\")\naxs[0].legend()\n\n# Treatment group histogram\naxs[1].hist(treatment_group, bins=30, color='#00008b', edgecolor='black')\naxs[1].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_treat:.2f}\")\naxs[1].set_title(\"Treatment Group\")\naxs[1].set_xlabel(\"Donation Amount\")\naxs[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDonation Amounts (Conditional on Giving) by Treatment Status\n\n\n\n\n\n\n\nThe histograms of donation amounts (conditional on giving) reveal that while both groups exhibit right-skewed giving patterns, the treatment group gave slightly less on average than the control group. This confirms earlier regression and t-test findings, where the treatment group’s mean donation was ~$1.67 lower and not statistically significant. Thus, the treatment appears to have increased participation, but not the amount given per donor."
  },
  {
    "objectID": "Homework1/hw1_questions.html#simulation-experiment",
    "href": "Homework1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic works, this section uses simulation to demonstrate two core statistical concepts:\n\nThe Law of Large Numbers (LLN)\n\nThe Central Limit Theorem (CLT)\n\nSuppose the true distribution of respondents who do not receive a charitable donation match is modeled as a Bernoulli distribution with probability:\n[ p = 0.018 ]\nThis means 1.8% of people in the control group are expected to donate.\nFurther, suppose that the distribution of respondents who do receive a charitable donation match of any size is also Bernoulli, with:\n[ p = 0.022 ]\nThis reflects a 2.2% donation probability in the treatment group. These values reflect the observed response rates in the experiment.\nThe following simulations explore: - How repeated sampling stabilizes around the true treatment effect (LLN) - How the sampling distribution of mean differences becomes approximately normal (CLT)\n\nLaw of Large Numbers\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set the true probabilities (based on your data)\np_control = 0.0179  # 1.79% donation rate\np_treatment = 0.0220  # 2.20% donation rate\n\n# Simulate 10,000 differences in donation rates\nnp.random.seed(42)\nn = 10000\ncontrol_draws = np.random.binomial(1, p_control, n)\ntreatment_draws = np.random.binomial(1, p_treatment, n)\n\ndiffs = treatment_draws - control_draws\n\n# Cumulative average of the differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)\n\n# Plot\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative Avg. Difference\", linewidth=1.5)\nplt.axhline(p_treatment - p_control, color='red', linestyle='--', label=\"True Difference\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Avg. (Treatment - Control)\")\nplt.title(\"Law of Large Numbers in Action\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nLaw of Large Numbers: Cumulative Average of Donation Rate Differences\n\n\n\n\n\n\n\nThe plot shows how the cumulative average difference in donation rates between the simulated treatment and control groups stabilizes over time. Initially, there is substantial fluctuation, but as the number of simulations increases, the cumulative average converges to the true difference in population means (approximately 0.0041).\nThis visualization demonstrates the Law of Large Numbers: as sample size increases, the average of the observed differences converges to the expected (true) value. In the context of this experiment, it reinforces that large-scale testing (like Karlan & List’s 50,000+ mailings) provides stable and trustworthy estimates of treatment effects.\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set true probabilities\np_control = 0.0179\np_treatment = 0.0220\ntrue_diff = p_treatment - p_control\n\n# Set sample sizes\nsample_sizes = [50, 200, 500, 1000]\n\n# Setup for plotting\nfig, axs = plt.subplots(4, 1, figsize=(8, 10))\naxs = axs.flatten()\n\nnp.random.seed(42)\n\n# Loop over each sample size\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(1000):\n        c_sample = np.random.binomial(1, p_control, n)\n        t_sample = np.random.binomial(1, p_treatment, n)\n        diff = t_sample.mean() - c_sample.mean()\n        diffs.append(diff)\n\n    axs[i].hist(diffs, bins=30, color='#add8e6', edgecolor='black')\n    axs[i].axvline(true_diff, color='red', linestyle='--', linewidth=2, label='True Diff')\n    axs[i].axvline(0, color='black', linestyle=':', linewidth=1, label='Zero')\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Mean Difference\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nCentral Limit Theorem: Distribution of Mean Differences Across Sample Sizes\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem: Interpretation\nThese four histograms show the distribution of average donation rate differences between treatment and control groups, across 1,000 simulations, for sample sizes of 50, 200, 500, and 1000.\n\nAt n = 50, the distribution is wide and somewhat lumpy — sampling variation dominates, and zero is often near the center.\nAs sample size increases, the distribution becomes tighter and more symmetric.\nBy n = 1000, the distribution of differences is sharply centered around the true difference, and zero is clearly in the tail.\n\nThis illustrates the Central Limit Theorem: with large enough samples, the distribution of sample means (or mean differences) is approximately normal, even if the underlying data is binary.\nIn this context, it shows how small effects can be confidently detected with large sample sizes, as demonstrated in Karlan & List’s field experiment."
  },
  {
    "objectID": "Homework1/hw1_questions.html#interpretation-3",
    "href": "Homework1/hw1_questions.html#interpretation-3",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Interpretation",
    "text": "Interpretation\nI restricted the analysis to only those individuals who made a donation (gave == 1) and ran a t-test and bivariate regression to compare donation amounts between treatment and control groups.\nInterestingly, the average amount given was actually slightly lower in the treatment group than in the control group (by ~$1.67), but this difference was not statistically significant (p ≈ 0.56).\nThese results suggest that while the treatment increased the likelihood of giving, it did not increase the amount given among those who chose to donate. In fact, it may have had a weak negative effect — though we cannot confidently conclude that from this data.\nThis supports the paper’s claim that matching offers are most effective at increasing participation (extensive margin) rather than increasing the donation amount (intensive margin).\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Subset to people who donated\ndf_donors = df[df[\"gave\"] == 1].copy()\n\n# Drop NAs just in case\ndf_donors = df_donors.dropna(subset=[\"amount\", \"treatment\"])\n\n# T-test\namount_treated = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\namount_control = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val = ttest_ind(amount_treated, amount_control, equal_var=False)\n\n# Regression\nmodel = smf.ols(\"amount ~ treatment\", data=df_donors).fit()\n\n# Summarize results\nsummary_df = pd.DataFrame({\n    \"Control Mean\": [amount_control.mean()],\n    \"Treatment Mean\": [amount_treated.mean()],\n    \"Difference (T-test)\": [amount_treated.mean() - amount_control.mean()],\n    \"T-statistic\": [round(t_stat, 4)],\n    \"T-test P-value\": [round(p_val, 4)],\n    \"Regression Coefficient\": [model.params[\"treatment\"]],\n    \"Regression P-value\": [model.pvalues[\"treatment\"]]\n}).round(4)\n\nsummary_df\n\n\n\n\n\n\n\n\n\nControl Mean\nTreatment Mean\nDifference (T-test)\nT-statistic\nT-test P-value\nRegression Coefficient\nRegression P-value\n\n\n\n\n0\n45.540298\n43.871899\n-1.6684\n-0.5846\n0.559\n-1.6684\n0.5615"
  },
  {
    "objectID": "Homework1/hw1_questions.html#does-the-treatment-coefficient-have-a-causal-interpretation",
    "href": "Homework1/hw1_questions.html#does-the-treatment-coefficient-have-a-causal-interpretation",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Does the treatment coefficient have a causal interpretation?",
    "text": "Does the treatment coefficient have a causal interpretation?\nYes — because treatment was randomly assigned, the coefficient reflects a causal effect of treatment on donation amount, conditional on giving\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Filter: only people who donated\ndf_donors = df[df[\"gave\"] == 1]\n\n# Split by group\ntreatment_group = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\ncontrol_group = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\n\n# Means\nmean_treat = treatment_group.mean()\nmean_control = control_group.mean()\n\n# Plot\nfig, axs = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\n# Control group histogram\naxs[0].hist(control_group, bins=30, color='skyblue', edgecolor='black')\naxs[0].axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_control:.2f}\")\naxs[0].set_title(\"Control Group\")\naxs[0].set_xlabel(\"Donation Amount\")\naxs[0].set_ylabel(\"Number of Donors\")\naxs[0].legend()\n\n# Treatment group histogram\naxs[1].hist(treatment_group, bins=30, color='lightgreen', edgecolor='black')\naxs[1].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_treat:.2f}\")\naxs[1].set_title(\"Treatment Group\")\naxs[1].set_xlabel(\"Donation Amount\")\naxs[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDonation Amounts (Conditional on Giving) by Treatment Status\n\n\n\n\nThe histograms of donation amounts (conditional on giving) reveal that while both groups exhibit right-skewed giving patterns, the treatment group gave slightly less on average than the control group. This confirms earlier regression and t-test findings, where the treatment group’s mean donation was ~$1.67 lower and not statistically significant. Thus, the treatment appears to have increased participation, but not the amount given per donor."
  },
  {
    "objectID": "Homework1/hw1_questions.html#interpretation-4",
    "href": "Homework1/hw1_questions.html#interpretation-4",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Interpretation",
    "text": "Interpretation\nThese four histograms show the distribution of average donation rate differences between treatment and control groups, across 1000 simulations, for sample sizes of 50, 200, 500, and 1000.\nAt n = 50, the distribution is wide and somewhat lumpy — sampling variation dominates, and zero is often near the center.\nAs sample size increases, the distribution becomes tighter and more symmetric.\nBy n = 1000, the distribution of differences is sharply centered around the true difference, and zero is clearly in the tail.\nThis illustrates the Central Limit Theorem: with large enough samples, the distribution of sample means (or mean differences) is approximately normal, even if the underlying data is binary. In this context, it shows how small effects can be confidently detected with large sample sizes, as seen in Karlan & List’s field experiment."
  },
  {
    "objectID": "Homework1/hw1_questions.html#balance-test",
    "href": "Homework1/hw1_questions.html#balance-test",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Balance Test",
    "text": "Balance Test\nAs an ad hoc test of the randomization mechanism, I conducted a series of comparisons between the treatment and control groups to assess whether they differ significantly on key pre-treatment characteristics. This helps confirm whether the random assignment of treatment was implemented correctly.\nTo verify that treatment was randomly assigned, I tested whether the following pre-treatment variables differed between the two groups:\n\nmrm2: Months since last donation\n\nfreq: Number of prior donations\n\nfemale: Gender indicator (1 = female)\n\nhpa: Highest previous contribution\n\nFor each variable, I conducted both:\n\nA two-sample t-test, and\n\nA simple linear regression of the form:\n\n\nResult\nNone of the tested variables show statistically significant differences between the treatment and control groups at the 95% confidence level. The t-test and regression results are consistent, confirming that randomization appears to have worked as intended.\nThis balance check serves the same purpose as Table 1 in the original paper: it shows that treatment assignment was not systematically related to baseline characteristics. This supports the causal interpretation of treatment effects on outcomes later in the analysis.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load the .dta file (if not already in CSV)\ndta_file = 'karlan_list_2007.dta'\ndf = pd.read_stata(dta_file)\n\n# Select variables to test for balance\nvars_to_test = ['mrm2', 'freq', 'female', 'hpa']\ndf_clean = df[['treatment'] + vars_to_test].dropna()\n\n# Initialize lists for storing results\nt_test_results = []\nregression_results = []\n\nfor var in vars_to_test:\n    # Separate treatment and control groups\n    treat_group = df_clean[df_clean['treatment'] == 1][var]\n    control_group = df_clean[df_clean['treatment'] == 0][var]\n\n    # Two-sample t-test (Welch's t-test)\n    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)\n\n    # Simple linear regression\n    model = smf.ols(f\"{var} ~ treatment\", data=df_clean).fit()\n    coef = model.params['treatment']\n    reg_pval = model.pvalues['treatment']\n\n    # Store nicely formatted results\n    t_test_results.append({\n        \"Variable\": var,\n        \"T-test p-value\": round(t_pval, 4),\n        \"Significant (T-test)\": \"Yes\" if t_pval &lt; 0.05 else \"No\"\n    })\n\n    regression_results.append({\n        \"Variable\": var,\n        \"Regression coef\": round(coef, 4),\n        \"Regression p-value\": round(reg_pval, 4),\n        \"Significant (Regression)\": \"Yes\" if reg_pval &lt; 0.05 else \"No\"\n    })\n\n# Create DataFrames\nt_df = pd.DataFrame(t_test_results)\nr_df = pd.DataFrame(regression_results)\n\n# Print clean tables\nprint(\"=== T-Test Results ===\")\nprint(t_df.to_string(index=False))\n\nprint(\"\\n=== Linear Regression Results ===\")\nprint(r_df.to_string(index=False))\n\n\n=== T-Test Results ===\nVariable  T-test p-value Significant (T-test)\n    mrm2          0.9391                   No\n    freq          0.9524                   No\n  female          0.0786                   No\n     hpa          0.3132                   No\n\n=== Linear Regression Results ===\nVariable  Regression coef  Regression p-value Significant (Regression)\n    mrm2           0.0088              0.9391                       No\n    freq          -0.0066              0.9524                       No\n  female          -0.0076              0.0778                       No\n     hpa           0.6635              0.3274                       No"
  }
]